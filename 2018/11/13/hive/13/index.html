<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="HIVE调优之开发调优(2)"><meta name="keywords" content="Hive"><meta name="author" content="Tunan"><meta name="copyright" content="Tunan"><title>HIVE调优之开发调优(2) | TUNANのBlog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#目录"><span class="toc-number">1.</span> <span class="toc-text">目录</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop-框架计算特性"><span class="toc-number">2.</span> <span class="toc-text">Hadoop 框架计算特性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#优化常用手段"><span class="toc-number">3.</span> <span class="toc-text">优化常用手段</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#排序选择"><span class="toc-number">4.</span> <span class="toc-text">排序选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#怎样做笛卡尔积"><span class="toc-number">5.</span> <span class="toc-text">怎样做笛卡尔积</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#怎样写-in-exists-语句"><span class="toc-number">6.</span> <span class="toc-text">怎样写 in/exists 语句</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#设置合理的-maptask-数量"><span class="toc-number">7.</span> <span class="toc-text">设置合理的 maptask 数量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#小文件合并"><span class="toc-number">8.</span> <span class="toc-text">小文件合并</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#设置合理的-reduceTask-的数量"><span class="toc-number">9.</span> <span class="toc-text">设置合理的 reduceTask 的数量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#合并-MapReduce-操作"><span class="toc-number">10.</span> <span class="toc-text">合并 MapReduce 操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#合理利用分桶：Bucketing-和-Sampling"><span class="toc-number">11.</span> <span class="toc-text">合理利用分桶：Bucketing 和 Sampling</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#合理利用分区：Partition"><span class="toc-number">12.</span> <span class="toc-text">合理利用分区：Partition</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Join-优化"><span class="toc-number">13.</span> <span class="toc-text">Join 优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Group-By-优化"><span class="toc-number">14.</span> <span class="toc-text">Group By 优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Map-端部分聚合"><span class="toc-number">14.1.</span> <span class="toc-text">1. Map 端部分聚合</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-使用-Group-By-有数据倾斜的时候进行负载均衡"><span class="toc-number">14.2.</span> <span class="toc-text">2. 使用 Group By 有数据倾斜的时候进行负载均衡</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#合理利用文件存储格式"><span class="toc-number">15.</span> <span class="toc-text">合理利用文件存储格式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#本地模式执行-MapReduce"><span class="toc-number">16.</span> <span class="toc-text">本地模式执行 MapReduce</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#并行化处理"><span class="toc-number">17.</span> <span class="toc-text">并行化处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#设置压缩存储"><span class="toc-number">18.</span> <span class="toc-text">设置压缩存储</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-压缩的原因"><span class="toc-number">18.1.</span> <span class="toc-text">1. 压缩的原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-常用压缩方法对比"><span class="toc-number">18.2.</span> <span class="toc-text">2. 常用压缩方法对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-压缩方式的选择"><span class="toc-number">18.3.</span> <span class="toc-text">3. 压缩方式的选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-压缩使用"><span class="toc-number">18.4.</span> <span class="toc-text">4. 压缩使用</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/xiaoqi.jpg"></div><div class="author-info__name text-center">Tunan</div><div class="author-info__description text-center">BigData Developer</div><div class="follow-button"><a href="#">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">170</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">35</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">31</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="https://hadoop.apache.org/docs/r2.10.0/hadoop-project-dist/hadoop-common/SingleCluster.html" target="_blank" rel="noopener">HADOOP</a><a class="author-info-links__name text-center" href="https://cwiki.apache.org/confluence/display/Hive/" target="_blank" rel="noopener">HIVE</a><a class="author-info-links__name text-center" href="http://archive.cloudera.com/cdh5/cdh/5/" target="_blank" rel="noopener">CDH</a><a class="author-info-links__name text-center" href="http://flume.apache.org/" target="_blank" rel="noopener">FLUME</a><a class="author-info-links__name text-center" href="https://azkaban.github.io/" target="_blank" rel="noopener">AZKABAN</a><a class="author-info-links__name text-center" href="https://www.maxinhong.com/" target="_blank" rel="noopener">叶梨子</a><a class="author-info-links__name text-center" href="https://www.cnblogs.com/qingyunzong" target="_blank" rel="noopener">老铁</a><a class="author-info-links__name text-center" href="https://blog.csdn.net/jim8973/" target="_blank" rel="noopener">飞哥</a><a class="author-info-links__name text-center" href="https://vinxikk.github.io/" target="_blank" rel="noopener">vinx</a><a class="author-info-links__name text-center" href="http://dongxicheng.org/" target="_blank" rel="noopener">懂西成(Hadoop技术内幕作者)</a><a class="author-info-links__name text-center" href="https://www.cnblogs.com/xing901022/" target="_blank" rel="noopener">xingoo</a><a class="author-info-links__name text-center" href="https://www.cnblogs.com/itboys/tag/" target="_blank" rel="noopener">大葱拌豆腐</a><a class="author-info-links__name text-center" href="https://www.cnblogs.com/shishanyuan" target="_blank" rel="noopener">郭景瞻(图解Spark作者)</a><a class="author-info-links__name text-center" href="https://segmentfault.com/u/wishdaren_5c243b920a3eb" target="_blank" rel="noopener">Wish大人</a><a class="author-info-links__name text-center" href="https://www.cnblogs.com/huxi2b/" target="_blank" rel="noopener">huxi_2b(kafka)</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/soroush-golpoor-1497416-unsplash.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">TUNANのBlog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">HIVE调优之开发调优(2)</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-11-13</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Hive/">Hive</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">4.3k</span><span class="post-meta__separator">|</span><span>Reading time: 15 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol>
<li>Hadoop 框架计算特性</li>
<li>优化常用手段</li>
<li>排序选择</li>
<li>怎样做笛卡尔积</li>
<li>怎样写 in/exists 语句</li>
<li>设置合理的 maptask 数量</li>
<li>小文件合并</li>
<li>设置合理的 reduceTask 的数量</li>
<li>合理利用分桶：Bucketing 和 Sampling</li>
<li>合理利用分区：Partition </li>
<li>Join 优化</li>
<li>Group By 优化</li>
<li>合理利用文件存储格式 </li>
<li>本地模式执行 MapReduce</li>
<li>并行化处理</li>
<li>设置压缩存储</li>
</ol>
<h2 id="Hadoop-框架计算特性"><a href="#Hadoop-框架计算特性" class="headerlink" title="Hadoop 框架计算特性"></a>Hadoop 框架计算特性</h2><ol>
<li><p>数据量大不是问题，数据倾斜是个问题</p>
</li>
<li><p>jobs 数比较多的作业运行效率相对比较低，比如即使有几百行的表，如果多次关联多次 汇总，产生十几个 jobs，耗时很长。原因是 map reduce 作业初始化的时间是比较长的</p>
</li>
<li><p>sum,count,max,min 等 UDAF，不怕数据倾斜问题，hadoop 在 map 端的汇总合并优化，使 数据倾斜不成问题</p>
</li>
<li><p>count(distinct userid)，在数据量大的情况下，效率较低，如果是多 count(distinct userid,month)效率更低，因为 count(distinct)是按 group by 字段分组，按 distinct 字段排序， 一般这种分布方式是很倾斜的，比如 PV 数据，淘宝一天 30 亿的 pv，如果按性别分组，分 配 2 个 reduce，每个 reduce 期望处理 15 亿数据，但现实必定是男少女多</p>
</li>
</ol>
<h2 id="优化常用手段"><a href="#优化常用手段" class="headerlink" title="优化常用手段"></a>优化常用手段</h2><ol>
<li><p>好的模型设计事半功倍</p>
</li>
<li><p>解决数据倾斜问题</p>
</li>
<li><p>减少 job 数</p>
</li>
<li><p>设置合理的 MapReduce 的 task 数，能有效提升性能。(比如，10w+级别的计算，用 160个 reduce，那是相当的浪费，1 个足够)</p>
</li>
<li><p>了解数据分布，自己动手解决数据倾斜问题是个不错的选择。这是通用的算法优化，但 算法优化有时不能适应特定业务背景，开发人员了解业务，了解数据，可以通过业务逻辑精确有效的解决数据倾斜问题</p>
</li>
<li><p>数据量较大的情况下，慎用 count(distinct)，group by 容易产生倾斜问题</p>
</li>
<li><p>对小文件进行合并，是行之有效的提高调度效率的方法，假如所有的作业设置合理的文件数，对云梯的整体调度效率也会产生积极的正向影响</p>
</li>
<li><p>优化时把握整体，单个作业最优不如整体最优</p>
</li>
</ol>
<h2 id="排序选择"><a href="#排序选择" class="headerlink" title="排序选择"></a>排序选择</h2><ul>
<li><p><strong>cluster by</strong>：对同一字段分桶并排序，不能和 sort by 连用</p>
</li>
<li><p><strong>distribute by + sort by</strong>：分桶，保证同一字段值只存在一个结果文件当中，结合 sort by 保证 每个 reduceTask 结果有序</p>
</li>
<li><p><strong>sort by</strong>：单机排序，单个 reduce 结果有序</p>
</li>
<li><p><strong>order by</strong>：全局排序，缺陷是只能使用一个 reduce</p>
</li>
</ul>
<p><strong>一定要区分这四种排序的使用方式和适用场景</strong></p>
<h2 id="怎样做笛卡尔积"><a href="#怎样做笛卡尔积" class="headerlink" title="怎样做笛卡尔积"></a>怎样做笛卡尔积</h2><p>当 Hive 设定为严格模式（hive.mapred.mode=strict）时，不允许在 HQL 语句中出现笛卡尔积， 这实际说明了 Hive 对笛卡尔积支持较弱。因为找不到 Join key，Hive 只能使用 1 个 reducer 来完成笛卡尔积。</p>
<p>当然也可以使用 limit 的办法来减少某个表参与 join 的数据量，但对于需要笛卡尔积语义的 需求来说，经常是一个大表和一个小表的 Join 操作，结果仍然很大（以至于无法用单机处 理），这时 MapJoin才是最好的解决办法。MapJoin，顾名思义，会在 Map 端完成 Join 操作。 这需要将 Join 操作的一个或多个表完全读入内存。</p>
<p>PS：MapJoin 在子查询中可能出现未知 BUG。在大表和小表做笛卡尔积时，规避笛卡尔积的 方法是，给 Join 添加一个 Join key，<strong>原理很简单：将小表扩充一列 join key，并将小表的条目复制数倍，join</strong> <strong>key 各不相同；将大表扩充一列 join key 为随机数。</strong></p>
<p><strong>精髓就在于复制几倍，最后就有几个 reduce 来做，而且大表的数据是前面小表扩张 key 值 范围里面随机出来的，所以复制了几倍 n，就相当于这个随机范围就有多大 n，那么相应的， 大表的数据就被随机的分为了 n 份。并且最后处理所用的 reduce 数量也是 n，而且也不会出现数据倾斜。</strong></p>
<h2 id="怎样写-in-exists-语句"><a href="#怎样写-in-exists-语句" class="headerlink" title="怎样写 in/exists 语句"></a>怎样写 in/exists 语句</h2><p>虽然经过测验，hive1.2.1 也支持 in/exists 操作，但还是推荐使用 hive 的一个高效替代方案：<strong>left semi join</strong></p>
<p>比如说：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> a.id, a.name <span class="keyword">from</span> a <span class="keyword">where</span> a.id <span class="keyword">in</span> (<span class="keyword">select</span> b.id <span class="keyword">from</span> b);</span><br><span class="line"><span class="keyword">select</span> a.id, a.name <span class="keyword">from</span> a <span class="keyword">where</span> <span class="keyword">exists</span> (<span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> b <span class="keyword">where</span> a.id = b.id);</span><br></pre></td></tr></table></figure>

<p>应该转换成：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> a.id, a.name <span class="keyword">from</span> a <span class="keyword">left</span> <span class="keyword">semi</span> <span class="keyword">join</span> b <span class="keyword">on</span> a.id = b.id;</span><br></pre></td></tr></table></figure>



<h2 id="设置合理的-maptask-数量"><a href="#设置合理的-maptask-数量" class="headerlink" title="设置合理的 maptask 数量"></a>设置合理的 maptask 数量</h2><ol>
<li><p>Map 数过大</p>
<p>Map 阶段输出文件太小，产生大量小文件</p>
<p>初始化和创建 Map 的开销很大</p>
</li>
<li><p>Map 数太小</p>
<p>文件处理或查询并发度小，Job 执行时间过长</p>
<p>大量作业时，容易堵塞集群 </p>
</li>
</ol>
<p>在 MapReduce 的编程案例中，我们得知，一个MR Job的 MapTask 数量是由输入分片 InputSplit 决定的。而输入分片是由 FileInputFormat.getSplit()决定的。一个输入分片对应一个 MapTask， 而输入分片是由三个参数决定的：</p>
<p><img src="https://yerias.github.io/hive_img/%E8%AE%BE%E7%BD%AEmap%E4%BB%BB%E5%8A%A1%E6%95%B0%E9%87%8F.png" alt="设置map任务数量"></p>
<p>输入分片大小的计算是这么计算出来的：</p>
<p><strong>long splitSize = Math.max(minSize, Math.min(maxSize, blockSize))</strong></p>
<p>默认情况下，输入分片大小和 HDFS 集群默认数据块大小一致，也就是默认一个数据块，启 用一个 MapTask 进行处理，这样做的好处是避免了服务器节点之间的数据传输，提高 job 处理效率</p>
<p>两种经典的控制 MapTask 的个数方案：减少 MapTask 数或者增加 MapTask 数</p>
<ol>
<li>减少 MapTask 数是通过合并小文件来实现，这一点主要是针对数据源</li>
<li>增加 MapTask 数可以通过控制上一个 job 的 reduceTask 个数</li>
</ol>
<p>因为 Hive 语句最终要转换为一系列的 MapReduce Job 的，而每一个 MapReduce Job 是由一 系列的 MapTask 和 ReduceTask 组成的，默认情况下， MapReduce 中一个 MapTask 或者一个 ReduceTask 就会启动一个 JVM 进程，一个 Task 执行完毕后， JVM 进程就退出。这样如果任 务花费时间很短，又要多次启动 JVM 的情况下，JVM 的启动时间会变成一个比较大的消耗， 这个时候，就可以通过重用 JVM 来解决：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set mapred.job.reuse.jvm.num.tasks=5</span><br></pre></td></tr></table></figure>

<h2 id="小文件合并"><a href="#小文件合并" class="headerlink" title="小文件合并"></a>小文件合并</h2><p>文件数目过多，会给 HDFS 带来压力，并且会影响处理效率，可以通过合并 Map 和 Reduce 的 结果文件来消除这样的影响：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set hive.merge.mapfiles = true ##在 map only 的任务结束时合并小文件</span><br><span class="line">set hive.merge.mapredfiles = false ## true 时在 MapReduce 的任务结束时合并小文件</span><br><span class="line">set hive.merge.size.per.task = 256*1000*1000 ##合并文件的大小</span><br><span class="line">set mapred.max.split.size=256000000; ##每个 Map 最大分割大小</span><br><span class="line">set mapred.min.split.size.per.node=1; ##一个节点上 split 的最少值</span><br><span class="line">set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat; ##执行 Map 前进行小文件合并</span><br></pre></td></tr></table></figure>

<h2 id="设置合理的-reduceTask-的数量"><a href="#设置合理的-reduceTask-的数量" class="headerlink" title="设置合理的 reduceTask 的数量"></a>设置合理的 reduceTask 的数量</h2><p>Hadoop MapReduce 程序中，reducer 个数的设定极大影响执行效率，这使得 Hive 怎样决定 reducer 个数成为一个关键问题。遗憾的是 Hive 的估计机制很弱，不指定 reducer 个数的情 况下，Hive 会猜测确定一个 reducer 个数，基于以下两个设定：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hive.exec.reducers.bytes.per.reducer（默认为 256000000）</span><br><span class="line">hive.exec.reducers.max（默认为 1009）</span><br><span class="line">mapreduce.job.reduces=-1（设置一个常量 reducetask 数量）</span><br></pre></td></tr></table></figure>

<p>计算 reducer 数的公式很简单： N=min(参数 2，总输入数据量/参数 1) 通常情况下，有必要手动指定 reducer 个数。考虑到 map 阶段的输出数据量通常会比输入有大幅减少，因此即使不设定 reducer 个数，重设参数 2 还是必要的。</p>
<p><strong>依据 Hadoop 的经验，可以将参数 2 设定为 0.95*(集群中 datanode 个数)。</strong> </p>
<h2 id="合并-MapReduce-操作"><a href="#合并-MapReduce-操作" class="headerlink" title="合并 MapReduce 操作"></a>合并 MapReduce 操作</h2><p>Multi-group by 是 Hive 的一个非常好的特性，它使得 Hive 中利用中间结果变得非常方便。 例如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">FROM (<span class="keyword">SELECT</span> a.status, b.school, b.gender <span class="keyword">FROM</span> status_updates a <span class="keyword">JOIN</span> <span class="keyword">profiles</span> b <span class="keyword">ON</span> (a.userid =</span><br><span class="line">b.userid <span class="keyword">and</span> a.ds=<span class="string">'2009-03-20'</span> ) ) subq1</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> gender_summary <span class="keyword">PARTITION</span>(ds=<span class="string">'2009-03-20'</span>)</span><br><span class="line"><span class="keyword">SELECT</span> subq1.gender, <span class="keyword">COUNT</span>(<span class="number">1</span>) <span class="keyword">GROUP</span> <span class="keyword">BY</span> subq1.gender</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> school_summary <span class="keyword">PARTITION</span>(ds=<span class="string">'2009-03-20'</span>)</span><br><span class="line"><span class="keyword">SELECT</span> subq1.school, <span class="keyword">COUNT</span>(<span class="number">1</span>) <span class="keyword">GROUP</span> <span class="keyword">BY</span> subq1.school</span><br></pre></td></tr></table></figure>

<p>上述查询语句使用了 multi-group by 特性连续 group by 了 2 次数据，使用不同的 group by key。 这一特性可以减少一次 MapReduce 操作</p>
<h2 id="合理利用分桶：Bucketing-和-Sampling"><a href="#合理利用分桶：Bucketing-和-Sampling" class="headerlink" title="合理利用分桶：Bucketing 和 Sampling"></a>合理利用分桶：Bucketing 和 Sampling</h2><p>Bucket 是指将数据以指定列的值为 key 进行 hash，hash 到指定数目的桶中。这样就可以支 持高效采样了。如下例就是以 userid 这一列为 bucket 的依据，共设置 32 个 buckets</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> page_view(viewTime <span class="built_in">INT</span>, userid <span class="built_in">BIGINT</span>,</span><br><span class="line"> page_url <span class="keyword">STRING</span>, referrer_url <span class="keyword">STRING</span>,</span><br><span class="line"> ip <span class="keyword">STRING</span> <span class="keyword">COMMENT</span> <span class="string">'IP Address of the User'</span>)</span><br><span class="line"> <span class="keyword">COMMENT</span> <span class="string">'This is the page view table'</span></span><br><span class="line"> PARTITIONED <span class="keyword">BY</span>(dt <span class="keyword">STRING</span>, country <span class="keyword">STRING</span>)</span><br><span class="line"> CLUSTERED <span class="keyword">BY</span>(userid) SORTED <span class="keyword">BY</span>(viewTime) <span class="keyword">INTO</span> <span class="number">32</span> BUCKETS</span><br><span class="line"> <span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span></span><br><span class="line"> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'1'</span></span><br><span class="line"> COLLECTION ITEMS <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'2'</span></span><br><span class="line"> <span class="keyword">MAP</span> <span class="keyword">KEYS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'3'</span></span><br><span class="line"> <span class="keyword">STORED</span> <span class="keyword">AS</span> SEQUENCEFILE;</span><br></pre></td></tr></table></figure>

<p>通常情况下，Sampling 在全体数据上进行采样，这样效率自然就低，它要去访问所有数据。 而如果一个表已经对某一列制作了 bucket，就可以采样所有桶中指定序号的某个桶，这就 减少了访问量。</p>
<p>如下例所示就是采样了 page_view 中 32 个桶中的第三个桶的全部数据：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> page_view <span class="keyword">TABLESAMPLE</span>(<span class="keyword">BUCKET</span> <span class="number">3</span> <span class="keyword">OUT</span> <span class="keyword">OF</span> <span class="number">32</span>);</span><br></pre></td></tr></table></figure>

<p>如下例所示就是采样了 page_view 中 32 个桶中的第三个桶的一半数据：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> page_view <span class="keyword">TABLESAMPLE</span>(<span class="keyword">BUCKET</span> <span class="number">3</span> <span class="keyword">OUT</span> <span class="keyword">OF</span> <span class="number">64</span>);</span><br></pre></td></tr></table></figure>

<h2 id="合理利用分区：Partition"><a href="#合理利用分区：Partition" class="headerlink" title="合理利用分区：Partition"></a>合理利用分区：Partition</h2><p> Partition 就是分区。分区通过在创建表时启用 partitioned by 实现，用来 partition 的维度并不 是实际数据的某一列，具体分区的标志是由插入内容时给定的。当要查询某一分区的内容时 可以采用 where 语句，形似 where tablename.partition_column = a 来实现。</p>
<p>创建含分区的表</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> page_view(viewTime <span class="built_in">INT</span>, userid <span class="built_in">BIGINT</span>,</span><br><span class="line"> page_url <span class="keyword">STRING</span>, referrer_url <span class="keyword">STRING</span>,</span><br><span class="line"> ip <span class="keyword">STRING</span> <span class="keyword">COMMENT</span> <span class="string">'IP Address of the User'</span>)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span>(<span class="built_in">date</span> <span class="keyword">STRING</span>, country <span class="keyword">STRING</span>)</span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'1'</span></span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> TEXTFILE;</span><br></pre></td></tr></table></figure>

<p>载入内容，并指定分区标志</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/home/hadoop/pv_2008-06-08_us.txt'</span> <span class="keyword">into</span> <span class="keyword">table</span> page_view</span><br><span class="line"><span class="keyword">partition</span>(<span class="built_in">date</span>=<span class="string">'2008-06-08'</span>, country=<span class="string">'US'</span>);</span><br></pre></td></tr></table></figure>

<p>查询指定标志的分区内容</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> page_views.* <span class="keyword">FROM</span> page_views</span><br><span class="line"> <span class="keyword">WHERE</span> page_views.date &gt;= <span class="string">'2008-03-01'</span> <span class="keyword">AND</span> page_views.date &lt;= <span class="string">'2008-03-31'</span> <span class="keyword">AND</span></span><br><span class="line">page_views.referrer_url <span class="keyword">like</span> <span class="string">'%xyz.com'</span>;</span><br></pre></td></tr></table></figure>

<h2 id="Join-优化"><a href="#Join-优化" class="headerlink" title="Join 优化"></a>Join 优化</h2><p>总体原则：</p>
<ol>
<li><p>优先过滤后再进行 Join 操作，最大限度的减少参与 join 的数据量</p>
</li>
<li><p>小表 join 大表，最好启动 mapjoin</p>
</li>
<li><p>Join on 的条件相同的话，最好放入同一个 job，并且 join 表的排列顺序从小到大 </p>
</li>
</ol>
<p><strong>在使用写有 Join 操作的查询语句时有一条原则：应该将条目少的表/子查询放在 Join 操作 符的左边。</strong>原因是在 Join 操作的 Reduce 阶段，位于 Join 操作符左边的表的内容会被加 载进内存，将条目少的表放在左边，可以有效减少发生 OOM 错误的几率。对于一条语句 中有多个 Join 的情况，如果 Join 的条件相同，比如查询</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> pv_users</span><br><span class="line"><span class="keyword">SELECT</span> pv.pageid, u.age <span class="keyword">FROM</span> page_view p</span><br><span class="line"><span class="keyword">JOIN</span> <span class="keyword">user</span> u <span class="keyword">ON</span> (pv.userid = u.userid)</span><br><span class="line"><span class="keyword">JOIN</span> newuser x <span class="keyword">ON</span> (u.userid = x.userid);</span><br></pre></td></tr></table></figure>

<p>如果 Join 的 key 相同，不管有多少个表，都会则会合并为一个 Map-Reduce 任务，而不 是”n”个，在做 OUTER JOIN 的时候也是一样</p>
<p>如果 join 的条件不相同，比如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> pv_users</span><br><span class="line"> <span class="keyword">SELECT</span> pv.pageid, u.age <span class="keyword">FROM</span> page_view p</span><br><span class="line"> <span class="keyword">JOIN</span> <span class="keyword">user</span> u <span class="keyword">ON</span> (pv.userid = u.userid)</span><br><span class="line"> <span class="keyword">JOIN</span> newuser x <span class="keyword">on</span> (u.age = x.age);</span><br></pre></td></tr></table></figure>

<p>Map-Reduce 的任务数目和 Join 操作的数目是对应的，上述查询和以下查询是等价的</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--先 page_view 表和 user 表做链接</span></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tmptable</span><br><span class="line"> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> page_view p <span class="keyword">JOIN</span> <span class="keyword">user</span> u <span class="keyword">ON</span> (pv.userid = u.userid);</span><br><span class="line"><span class="comment">-- 然后结果表 temptable 和 newuser 表做链接</span></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> pv_users</span><br><span class="line"> <span class="keyword">SELECT</span> x.pageid, x.age <span class="keyword">FROM</span> tmptable x <span class="keyword">JOIN</span> newuser y <span class="keyword">ON</span> (x.age = y.age);</span><br></pre></td></tr></table></figure>

<p>在编写 Join 查询语句时，如果确定是由于 join 出现的数据倾斜，那么请做如下设置：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set hive.skewjoin.key=100000; // 这个是 join 的键对应的记录条数超过这个值则会进行 分拆，值根据具体数据量设置</span><br><span class="line">set hive.optimize.skewjoin=true; // 如果是 join 过程出现倾斜应该设置为 true</span><br></pre></td></tr></table></figure>

<h2 id="Group-By-优化"><a href="#Group-By-优化" class="headerlink" title="Group By 优化"></a>Group By 优化</h2><h3 id="1-Map-端部分聚合"><a href="#1-Map-端部分聚合" class="headerlink" title="1. Map 端部分聚合"></a>1. Map 端部分聚合</h3><p>并不是所有的聚合操作都需要在 Reduce 端完成，很多聚合操作都可以先在 Map 端进 行部分聚合，最后在Reduce 端得出最终结果。</p>
<p>MapReduce 的 combiner 组件参数包括：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set hive.map.aggr = true 是否在 Map 端进行聚合，默认为 True</span><br><span class="line">set hive.groupby.mapaggr.checkinterval = 100000 在 Map 端进行聚合操作的条目数目</span><br></pre></td></tr></table></figure>

<h3 id="2-使用-Group-By-有数据倾斜的时候进行负载均衡"><a href="#2-使用-Group-By-有数据倾斜的时候进行负载均衡" class="headerlink" title="2. 使用 Group By 有数据倾斜的时候进行负载均衡"></a>2. 使用 Group By 有数据倾斜的时候进行负载均衡</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set hive.groupby.skewindata = true</span><br></pre></td></tr></table></figure>

<p>当 sql 语句使用 groupby 时数据出现倾斜时，如果该变量设置为 true，那么 Hive 会自动进行 负载均衡。<strong>策略就是把 MR 任务拆分成两个：第一个先做预汇总，第二个再做最终汇总</strong></p>
<p>在 MR 的第一个阶段中，Map 的输出结果集合会缓存到 maptaks 中，每个 Reduce 做部分聚 合操作，并输出结果，这样处理的结果是相同 Group By Key 有可能被分发到不同的 Reduce 中， 从而达到负载均衡的目的；第二个阶段 再根据预处理的数据结果按照 Group By Key 分布到 Reduce 中（这个过程可以保证相同的 Group By Key 被分布到同一个 Reduce 中），最后完成 最终的聚合操作。</p>
<h2 id="合理利用文件存储格式"><a href="#合理利用文件存储格式" class="headerlink" title="合理利用文件存储格式"></a>合理利用文件存储格式</h2><p>创建表时，尽量使用 orc、parquet 这些列式存储格式，因为列式存储的表，每一列的数据在 物理上是存储在一起的，Hive 查询时会只遍历需要列数据，大大减少处理的数据量。</p>
<h2 id="本地模式执行-MapReduce"><a href="#本地模式执行-MapReduce" class="headerlink" title="本地模式执行 MapReduce"></a>本地模式执行 MapReduce</h2><p>Hive 在集群上查询时，默认是在集群上 N 台机器上运行， 需要多个机器进行协调运行，这 个方式很好地解决了大数据量的查询问题。但是当 Hive 查询处理的数据量比较小时，其实 没有必要启动分布式模式去执行，因为以分布式方式执行就涉及到跨网络传输、多节点协调 等，并且消耗资源。这个时间可以只使用本地模式来执行 mapreduce job，只在一台机器上 执行，速度会很快。启动本地模式涉及到三个参数：</p>
<p><img src="https://yerias.github.io/hive_img/%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F.png" alt="本地模式"></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set hive.exec.mode.local.auto=true 是打开 hive 自动判断是否启动本地模式的开关，但是只 是打开这个参数并不能保证启动本地模式，要当 map 任务数不超过</span><br><span class="line">hive.exec.mode.local.auto.input.files.max 的个数并且 map 输入文件大小不超过</span><br><span class="line">hive.exec.mode.local.auto.inputbytes.max 所指定的大小时，才能启动本地模式。</span><br></pre></td></tr></table></figure>

<h2 id="并行化处理"><a href="#并行化处理" class="headerlink" title="并行化处理"></a>并行化处理</h2><p>一个 hive sql 语句可能会转为多个 mapreduce Job，每一个 job 就是一个 stage，这些 job 顺序 执行，这个在 cli 的运行日志中也可以看到。但是有时候这些任务之间并不是是相互依赖的， 如果集群资源允许的话，可以让多个并不相互依赖 stage 并发执行，这样就节约了时间，提 高了执行速度，但是如果集群资源匮乏时，启用并行化反倒是会导致各个 job 相互抢占资源 而导致整体执行性能的下降。启用并行化：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.parallel=<span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.exec.parallel.thread.number=<span class="number">8</span>; //同一个 sql 允许并行任务的最大线程数</span><br></pre></td></tr></table></figure>

<h2 id="设置压缩存储"><a href="#设置压缩存储" class="headerlink" title="设置压缩存储"></a>设置压缩存储</h2><h3 id="1-压缩的原因"><a href="#1-压缩的原因" class="headerlink" title="1. 压缩的原因"></a>1. 压缩的原因</h3><p>Hive 最终是转为 MapReduce 程序来执行的，而 MapReduce 的性能瓶颈在于网络 IO 和 磁盘 IO，要解决性能瓶颈，最主要的是减少数据量，对数据进行压缩是个好的方式。压缩 虽然是减少了数据量，但是压缩过程要消耗 CPU 的，但是在 Hadoop 中， 往往性能瓶颈不 在于 CPU，CPU 压力并不大，所以压缩充分利用了比较空闲的 CPU</p>
<h3 id="2-常用压缩方法对比"><a href="#2-常用压缩方法对比" class="headerlink" title="2. 常用压缩方法对比"></a>2. 常用压缩方法对比</h3><p><img src="https://yerias.github.io/hive_img/%E5%8E%8B%E7%BC%A9%E6%A0%BC%E5%BC%8F%E5%AF%B9%E6%AF%94.png" alt="压缩格式对比"></p>
<p>各个压缩方式所对应的 Class 类：</p>
<p><img src="https://yerias.github.io/hive_img/%E5%8E%8B%E7%BC%A9%E6%A0%BC%E5%BC%8F%E5%AF%B9%E5%BA%94%E7%9A%84%E7%B1%BB.png" alt="压缩格式对应的类"></p>
<h3 id="3-压缩方式的选择"><a href="#3-压缩方式的选择" class="headerlink" title="3. 压缩方式的选择"></a>3. 压缩方式的选择</h3><ol>
<li><p>压缩比率</p>
<p><img src="https://yerias.github.io/hadoop_img/%E5%8E%8B%E7%BC%A9%E6%AF%94.png" alt="压缩比"></p>
</li>
<li><p>压缩解压缩速度</p>
<p><img src="https://yerias.github.io/hadoop_img/%E5%8E%8B%E7%BC%A9%E6%97%B6%E9%97%B4.png" alt="压缩时间"></p>
</li>
<li><p>是否支持 Split</p>
<p><img src="https://yerias.github.io/hadoop_img/%E5%8E%8B%E7%BC%A9.png" alt="压缩"></p>
</li>
</ol>
<h3 id="4-压缩使用"><a href="#4-压缩使用" class="headerlink" title="4. 压缩使用"></a>4. 压缩使用</h3><p>Job 输出文件按照 block 以 GZip 的方式进行压缩：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set mapreduce.output.fileoutputformat.compress=true // 默认值是 false</span><br><span class="line">set mapreduce.output.fileoutputformat.compress.type=BLOCK // 默认值是 Record</span><br><span class="line">set mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.GzipCodec // 默认值是 org.apache.hadoop.io.compress.DefaultCodec</span><br></pre></td></tr></table></figure>

<p>Map 输出结果也以 Gzip 进行压缩：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set mapred.map.output.compress=true</span><br><span class="line">set mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.GzipCodec // 默认值是 org.apache.hadoop.io.compress.DefaultCodec</span><br></pre></td></tr></table></figure>

<p>对 Hive 输出结果和中间都进行压缩：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set hive.exec.compress.output=true // 默认值是 false，不压缩</span><br><span class="line">set hive.exec.compress.intermediate=true // 默认值是 false，为 true 时 MR 设置的压缩才启用</span><br></pre></td></tr></table></figure></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined" target="_blank" rel="noopener">Tunan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yerias.github.io/2018/11/13/hive/13/">http://yerias.github.io/2018/11/13/hive/13/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hive/">Hive</a></div><div class="social-share" data-disabled="facebook,twitter,douban,linkedin,diandian"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2018/11/14/hive/14/"><i class="fa fa-chevron-left">  </i><span>Idea加载Hive源码，并且在控制台查询SQL</span></a></div><div class="next-post pull-right"><a href="/2018/11/12/hive/9/"><span>HIVE调优之开发调优(1)</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(/img/soroush-golpoor-1497416-unsplash.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2020 By Tunan</div><div class="framework-info"><span>Driven - </span><a href="#"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="#"><span>Melody</span></a></div><div class="footer_custom_text">大家好，我是图南，很高兴认识你们！</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script src="/js/search/local-search.js"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>