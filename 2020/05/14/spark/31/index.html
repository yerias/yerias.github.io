<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Spark内存管理"><meta name="keywords" content="Spark"><meta name="author" content="Tunan"><meta name="copyright" content="Tunan"><title>Spark内存管理 | TUNANのBlog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#概述"><span class="toc-number">1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#堆内和堆外内存规划"><span class="toc-number">2.</span> <span class="toc-text">堆内和堆外内存规划</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#堆内内存"><span class="toc-number">2.1.</span> <span class="toc-text">堆内内存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#堆外内存"><span class="toc-number">2.2.</span> <span class="toc-text">堆外内存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#内存管理接口"><span class="toc-number">2.3.</span> <span class="toc-text">内存管理接口</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#内存空间分配"><span class="toc-number">3.</span> <span class="toc-text">内存空间分配</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#静态内存管理"><span class="toc-number">3.1.</span> <span class="toc-text">静态内存管理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#统一内存管理"><span class="toc-number">3.2.</span> <span class="toc-text">统一内存管理</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/xiaoqi.jpg"></div><div class="author-info__name text-center">Tunan</div><div class="author-info__description text-center">BigData Developer</div><div class="follow-button"><a href="#">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">139</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">31</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">27</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="https://hadoop.apache.org/docs/r2.10.0/hadoop-project-dist/hadoop-common/SingleCluster.html" target="_blank" rel="noopener">HADOOP</a><a class="author-info-links__name text-center" href="https://cwiki.apache.org/confluence/display/Hive/" target="_blank" rel="noopener">HIVE</a><a class="author-info-links__name text-center" href="http://archive.cloudera.com/cdh5/cdh/5/" target="_blank" rel="noopener">CDH</a><a class="author-info-links__name text-center" href="http://flume.apache.org/" target="_blank" rel="noopener">FLUME</a><a class="author-info-links__name text-center" href="https://azkaban.github.io/" target="_blank" rel="noopener">AZKABAN</a><a class="author-info-links__name text-center" href="https://www.maxinhong.com/" target="_blank" rel="noopener">叶梨子</a><a class="author-info-links__name text-center" href="https://www.cnblogs.com/qingyunzong" target="_blank" rel="noopener">老铁</a><a class="author-info-links__name text-center" href="https://blog.csdn.net/jim8973/" target="_blank" rel="noopener">飞哥</a><a class="author-info-links__name text-center" href="https://vinxikk.github.io/" target="_blank" rel="noopener">vinx</a><a class="author-info-links__name text-center" href="http://dongxicheng.org/" target="_blank" rel="noopener">懂西成(Hadoop技术内幕作者)</a><a class="author-info-links__name text-center" href="https://www.cnblogs.com/xing901022/" target="_blank" rel="noopener">xingoo</a><a class="author-info-links__name text-center" href="https://www.cnblogs.com/itboys/tag/" target="_blank" rel="noopener">大葱拌豆腐</a><a class="author-info-links__name text-center" href="https://www.cnblogs.com/shishanyuan" target="_blank" rel="noopener">郭景瞻(图解Spark作者)</a><a class="author-info-links__name text-center" href="https://segmentfault.com/u/wishdaren_5c243b920a3eb" target="_blank" rel="noopener">Wish大人</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/soroush-golpoor-1497416-unsplash.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">TUNANのBlog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">Spark内存管理</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-05-14</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Spark/">Spark</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">3.1k</span><span class="post-meta__separator">|</span><span>Reading time: 10 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Spark 作为一个基于内存的分布式计算引擎，其内存管理模块在整个系统中扮演着非常重要的角色。理解 Spark 内存管理的基本原理，有助于更好地开发 Spark 应用程序和进行性能调优。本文旨在梳理出 Spark 内存管理的脉络，抛砖引玉，引出读者对这个话题的深入探讨。本文中阐述的原理基于 Spark 2.1 版本，阅读本文需要读者有一定的 Spark 和 Java 基础，了解 RDD、Shuffle、JVM 等相关概念。</p>
<p>在执行 Spark 的应用程序时，Spark 集群会启动 Driver 和 Executor 两种 JVM 进程，前者为主控进程，负责创建 Spark 上下文，提交 Spark 作业（Job），并将作业转化为计算任务（Task），在各个 Executor 进程间协调任务的调度，后者负责在工作节点上执行具体的计算任务，并将结果返回给 Driver，同时为需要持久化的 RDD 提供存储功能[1]。由于 Driver 的内存管理相对来说较为简单，本文主要对 Executor 的内存管理进行分析，下文中的 Spark 内存均特指 Executor 的内存。</p>
<h2 id="堆内和堆外内存规划"><a href="#堆内和堆外内存规划" class="headerlink" title="堆内和堆外内存规划"></a>堆内和堆外内存规划</h2><p>作为一个 JVM 进程，Executor 的内存管理建立在 JVM 的内存管理之上，Spark 对 JVM 的堆内（On-heap）空间进行了更为详细的分配，以充分利用内存。同时，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，进一步优化了内存的使用。</p>
<p><img src="https://yerias.github.io/spark_img/memoryManager_1.png" alt=""></p>
<h3 id="堆内内存"><a href="#堆内内存" class="headerlink" title="堆内内存"></a>堆内内存</h3><p>堆内内存的大小，由 Spark 应用程序启动时的 –executor-memory 或 spark.executor.memory 参数配置。Executor 内运行的并发任务共享 JVM 堆内内存，这些任务在缓存 RDD 数据和广播（Broadcast）数据时占用的内存被规划为存储（Storage）内存，而这些任务在执行 Shuffle 时占用的内存被规划为执行（Execution）内存，剩余的部分不做特殊规划，那些 Spark 内部的对象实例，或者用户定义的 Spark 应用程序中的对象实例，均占用剩余的空间。不同的管理模式下，这三部分占用的空间大小各不相同（下面第 2 小节会进行介绍）。</p>
<p>Spark 对堆内内存的管理是一种逻辑上的”规划式”的管理，因为对象实例占用内存的申请和释放都由 JVM 完成，Spark 只能在申请后和释放前记录这些内存，我们来看其具体流程：</p>
<ul>
<li>申请内存：</li>
</ul>
<blockquote>
<ol>
<li>Spark 在代码中 new 一个对象实例</li>
<li>JVM 从堆内内存分配空间，创建对象并返回对象引用</li>
<li>Spark 保存该对象的引用，记录该对象占用的内存</li>
</ol>
</blockquote>
<ul>
<li>释放内存：</li>
</ul>
<blockquote>
<ol>
<li>Spark 记录该对象释放的内存，删除该对象的引用</li>
<li>等待 JVM 的垃圾回收机制释放该对象占用的堆内内存</li>
</ol>
</blockquote>
<p>我们知道，JVM 的对象可以以序列化的方式存储，序列化的过程是将对象转换为二进制字节流，本质上可以理解为将非连续空间的链式存储转化为连续空间或块存储，在访问时则需要进行序列化的逆过程——反序列化，将字节流转化为对象，序列化的方式可以节省存储空间，但增加了存储和读取时候的计算开销。</p>
<p>对于 Spark 中序列化的对象，由于是字节流的形式，其占用的内存大小可直接计算，而对于非序列化的对象，其占用的内存是通过周期性地采样近似估算而得，即并不是每次新增的数据项都会计算一次占用的内存大小，这种方法降低了时间开销但是有可能误差较大，导致某一时刻的实际内存有可能远远超出预期[2]。此外，在被 Spark 标记为释放的对象实例，很有可能在实际上并没有被 JVM 回收，导致实际可用的内存小于 Spark 记录的可用内存。所以 Spark 并不能准确记录实际可用的堆内内存，从而也就无法完全避免内存溢出（OOM, Out of Memory）的异常。</p>
<p>虽然不能精准控制堆内内存的申请和释放，但 Spark 通过对存储内存和执行内存各自独立的规划管理，可以决定是否要在存储内存里缓存新的 RDD，以及是否为新的任务分配执行内存，在一定程度上可以提升内存的利用率，减少异常的出现。</p>
<h3 id="堆外内存"><a href="#堆外内存" class="headerlink" title="堆外内存"></a>堆外内存</h3><p>为了进一步优化内存的使用以及提高 Shuffle 时排序的效率，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，存储经过序列化的二进制数据。利用 JDK Unsafe API（从 Spark 2.0 开始，在管理堆外的存储内存时不再基于 Tachyon，而是与堆外的执行内存一样，基于 JDK Unsafe API 实现[3]），Spark 可以直接操作系统堆外内存，减少了不必要的内存开销，以及频繁的 GC 扫描和回收，提升了处理性能。堆外内存可以被精确地申请和释放，而且序列化的数据占用的空间可以被精确计算，所以相比堆内内存来说降低了管理的难度，也降低了误差。</p>
<p>在默认情况下堆外内存并不启用，可通过配置 spark.memory.offHeap.enabled 参数启用，并由 spark.memory.offHeap.size 参数设定堆外空间的大小。除了没有 other 空间，堆外内存与堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存。</p>
<h3 id="内存管理接口"><a href="#内存管理接口" class="headerlink" title="内存管理接口"></a>内存管理接口</h3><p>Spark 为存储内存和执行内存的管理提供了统一的接口——MemoryManager，同一个 Executor 内的任务都调用这个接口的方法来申请或释放内存:</p>
<p>内存管理接口的主要方法</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//申请存储内存</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">acquireStorageMemory</span></span>(blockId: <span class="type">BlockId</span>, numBytes: <span class="type">Long</span>, memoryMode: <span class="type">MemoryMode</span>): <span class="type">Boolean</span></span><br><span class="line"><span class="comment">//申请展开内存</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">acquireUnrollMemory</span></span>(blockId: <span class="type">BlockId</span>, numBytes: <span class="type">Long</span>, memoryMode: <span class="type">MemoryMode</span>): <span class="type">Boolean</span></span><br><span class="line"><span class="comment">//申请执行内存</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">acquireExecutionMemory</span></span>(numBytes: <span class="type">Long</span>, taskAttemptId: <span class="type">Long</span>, memoryMode: <span class="type">MemoryMode</span>): <span class="type">Long</span></span><br><span class="line"><span class="comment">//释放存储内存</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">releaseStorageMemory</span></span>(numBytes: <span class="type">Long</span>, memoryMode: <span class="type">MemoryMode</span>): <span class="type">Unit</span></span><br><span class="line"><span class="comment">//释放执行内存</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">releaseExecutionMemory</span></span>(numBytes: <span class="type">Long</span>, taskAttemptId: <span class="type">Long</span>, memoryMode: <span class="type">MemoryMode</span>): <span class="type">Unit</span></span><br><span class="line"><span class="comment">//释放展开内存</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">releaseUnrollMemory</span></span>(numBytes: <span class="type">Long</span>, memoryMode: <span class="type">MemoryMode</span>): <span class="type">Unit</span></span><br></pre></td></tr></table></figure>

<p>我们看到，在调用这些方法时都需要指定其内存模式（MemoryMode），这个参数决定了是在堆内还是堆外完成这次操作。</p>
<p>MemoryManager 的具体实现上，Spark 1.6 之后默认为统一管理（<a href="https://github.com/apache/spark/blob/v2.1.0/core/src/main/scala/org/apache/spark/memory/UnifiedMemoryManager.scala" target="_blank" rel="noopener">Unified Memory Manager</a>）方式，1.6 之前采用的静态管理（<a href="https://github.com/apache/spark/blob/v2.1.0/core/src/main/scala/org/apache/spark/memory/StaticMemoryManager.scala" target="_blank" rel="noopener">Static Memory Manager</a>）方式仍被保留，可通过配置 spark.memory.useLegacyMode 参数启用。两种方式的区别在于对空间分配的方式，下面的第 3 小节会分别对这两种方式进行介绍。</p>
<h2 id="内存空间分配"><a href="#内存空间分配" class="headerlink" title="内存空间分配"></a>内存空间分配</h2><h3 id="静态内存管理"><a href="#静态内存管理" class="headerlink" title="静态内存管理"></a>静态内存管理</h3><p>在 Spark 最初采用的静态内存管理机制下，存储内存、执行内存和其他内存的大小在 Spark 应用程序运行期间均为固定的，但用户可以应用程序启动前进行配置，堆内内存的分配如图 所示：</p>
<p><img src="https://yerias.github.io/spark_img/memoryManager_2.png" alt=""></p>
<p>可以看到，可用的堆内内存的大小需要按照下面的方式计算：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">可用的存储内存 = systemMaxMemory * spark.storage.memoryFraction * spark.storage.safetyFraction</span><br><span class="line">可用的执行内存 = systemMaxMemory * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction</span><br></pre></td></tr></table></figure>

<p>其中 systemMaxMemory 取决于当前 JVM 堆内内存的大小，最后可用的执行内存或者存储内存要在此基础上与各自的 memoryFraction 参数和 safetyFraction 参数相乘得出。上述计算公式中的两个 safetyFraction 参数，其意义在于在逻辑上预留出 1-safetyFraction 这么一块保险区域，降低因实际内存超出当前预设范围而导致 OOM 的风险（上文提到，对于非序列化对象的内存采样估算会产生误差）。值得注意的是，这个预留的保险区域仅仅是一种逻辑上的规划，在具体使用时 Spark 并没有区别对待，和”其它内存”一样交给了 JVM 去管理。</p>
<p>堆外的空间分配较为简单，只有存储内存和执行内存，     所示。可用的执行内存和存储内存占用的空间大小直接由参数 spark.memory.storageFraction 决定，由于堆外内存占用的空间可以被精确计算，所以无需再设定保险区域。</p>
<p><img src="https://yerias.github.io/spark_img/memoryManager_3.png" alt=""></p>
<p>静态内存管理机制实现起来较为简单，但如果用户不熟悉 Spark 的存储机制，或没有根据具体的数据规模和计算任务或做相应的配置，很容易造成”一半海水，一半火焰”的局面，即存储内存和执行内存中的一方剩余大量的空间，而另一方却早早被占满，不得不淘汰或移出旧的内容以存储新的内容。由于新的内存管理机制的出现，这种方式目前已经很少有开发者使用，出于兼容旧版本的应用程序的目的，Spark 仍然保留了它的实现。</p>
<p>最后看一下静态内存管理的源码</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 老版本的静态内存管理机制，storage和excutor是单独的</span></span><br><span class="line"><span class="type">StaticMemoryManager</span>&#123;</span><br><span class="line">	getMaxExecutionMemory&#123;</span><br><span class="line">	    <span class="keyword">val</span> memoryFraction = conf.getDouble(<span class="string">"spark.shuffle.memoryFraction"</span>, <span class="number">0.2</span>)</span><br><span class="line">    	<span class="keyword">val</span> safetyFraction = conf.getDouble(<span class="string">"spark.shuffle.safetyFraction"</span>, <span class="number">0.8</span>)</span><br><span class="line">		(systemMaxMemory * memoryFraction * safetyFraction).toLong	<span class="number">1000</span>M*<span class="number">0.2</span>*<span class="number">0.8</span>=<span class="number">160</span>M</span><br><span class="line">	&#125;</span><br><span class="line">	getMaxStorageMemory&#123;</span><br><span class="line">	    <span class="keyword">val</span> systemMaxMemory = conf.getLong(<span class="string">"spark.testing.memory"</span>, <span class="type">Runtime</span>.getRuntime.maxMemory)</span><br><span class="line">    	<span class="keyword">val</span> memoryFraction = conf.getDouble(<span class="string">"spark.storage.memoryFraction"</span>, <span class="number">0.6</span>)</span><br><span class="line">    	<span class="keyword">val</span> safetyFraction = conf.getDouble(<span class="string">"spark.storage.safetyFraction"</span>, <span class="number">0.9</span>)</span><br><span class="line">    	(systemMaxMemory * memoryFraction * safetyFraction).toLong	<span class="number">1000</span>M*<span class="number">0.6</span>*<span class="number">0.9</span>=<span class="number">540</span>M</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="统一内存管理"><a href="#统一内存管理" class="headerlink" title="统一内存管理"></a>统一内存管理</h3><p>Spark 1.6 之后引入的统一内存管理机制，与静态内存管理的区别在于存储内存和执行内存共享同一块空间，可以动态占用对方的空闲区域</p>
<p><img src="https://yerias.github.io/spark_img/memoryManager_4.png" alt=""></p>
<p>Executor Memory：主要用于存放 Shuffle、Join、Sort、Aggregation 等计算过程中的临时数据<br>Storage Memory：主要用于存储 spark 的 cache 数据，例如RDD的缓存、unroll数据<br>Other Memory：主要用于存储 RDD 转换操作所需要的数据，例如 RDD 依赖等信息<br>Reserved Memory：系统预留内存，会用来存储Spark内部对象</p>
<p><img src="https://yerias.github.io/spark_img/memoryManager_5.png" alt=""></p>
<p>其中最重要的优化在于动态占用机制，其规则如下：</p>
<blockquote>
<ul>
<li>设定基本的存储内存和执行内存区域（spark.storage.storageFraction 参数），该设定确定了双方各自拥有的空间的范围</li>
<li>双方的空间都不足时，则存储到硬盘；若己方空间不足而对方空余时，可借用对方的空间;（存储空间不足是指不足以放下一个完整的 Block）</li>
<li>执行内存的空间被对方占用后，可让对方将占用的部分转存到硬盘，然后”归还”借用的空间</li>
<li>存储内存的空间被对方占用后，无法让对方”归还”，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂</li>
</ul>
</blockquote>
<p><img src="https://yerias.github.io/spark_img/memoryManager_6.png" alt=""></p>
<p>凭借统一内存管理机制，Spark 在一定程度上提高了堆内和堆外内存资源的利用率，降低了开发者维护 Spark 内存的难度，但并不意味着开发者可以高枕无忧。譬如，所以如果存储内存的空间太大或者说缓存的数据过多，反而会导致频繁的全量垃圾回收，降低任务执行时的性能，因为缓存的 RDD 数据通常都是长期驻留内存的 [5] 。所以要想充分发挥 Spark 的性能，需要开发者进一步了解存储内存和执行内存各自的管理方式和实现原理。</p>
<p>最后看一下统一内存管理的源码</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 新版本统一的内存管理，storage和excutor是共用的</span></span><br><span class="line"><span class="type">UnifiedMemoryManager</span>&#123;</span><br><span class="line">	<span class="keyword">val</span> maxMemory = getMaxMemory(conf)&#123;</span><br><span class="line">		<span class="keyword">val</span> systemMemory = conf.getLong(<span class="string">"spark.testing.memory"</span>, <span class="type">Runtime</span>.getRuntime.maxMemory)</span><br><span class="line">		<span class="keyword">val</span> reservedMemory = conf.getLong(<span class="string">"spark.testing.reservedMemory"</span>,<span class="keyword">if</span> (conf.contains(<span class="string">"spark.testing"</span>)) <span class="number">0</span> <span class="keyword">else</span> <span class="type">RESERVED_SYSTEM_MEMORY_BYTES</span>) <span class="number">300</span>M </span><br><span class="line">	&#125;</span><br><span class="line">	<span class="number">1000</span>M - <span class="number">300</span>M = <span class="number">700</span>M</span><br><span class="line">	<span class="keyword">val</span> usableMemory = systemMemory - reservedMemory</span><br><span class="line">    <span class="keyword">val</span> memoryFraction = conf.getDouble(<span class="string">"spark.memory.fraction"</span>, <span class="number">0.6</span>)</span><br><span class="line">    (usableMemory * memoryFraction).toLong <span class="number">700</span>*<span class="number">0.6</span> = <span class="number">420</span>M	exe和storage总共能用的</span><br><span class="line">    </span><br><span class="line">    storage (<span class="number">1000</span><span class="number">-300</span>)*<span class="number">0.6</span>*<span class="number">0.5</span>=<span class="number">210</span>M  	/executor <span class="number">210</span>M</span><br><span class="line">    onHeapStorageRegionSize = (maxMemory * conf.getDouble(<span class="string">"spark.memory.storageFraction"</span>, <span class="number">0.5</span>)).toLong,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined" target="_blank" rel="noopener">Tunan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yerias.github.io/2020/05/14/spark/31/">http://yerias.github.io/2020/05/14/spark/31/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Spark/">Spark</a></div><div class="social-share" data-disabled="facebook,twitter,douban,linkedin,diandian"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2020/05/18/flume/6/"><i class="fa fa-chevron-left">  </i><span>修改Flume源码使taildir source支持递归（可配置）</span></a></div><div class="next-post pull-right"><a href="/2020/05/10/flink/1/"><span>Flink整合CDH Hadoop编译&amp;简单测试</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(/img/soroush-golpoor-1497416-unsplash.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2020 By Tunan</div><div class="framework-info"><span>Driven - </span><a href="#"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="#"><span>Melody</span></a></div><div class="footer_custom_text">大家好，我是图南，很高兴认识你们！</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script src="/js/search/local-search.js"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>