<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="BigData Developer"><meta name="keywords" content="yerias,TUNANのBlog,BigData"><meta name="author" content="Tunan"><meta name="copyright" content="Tunan"><title>感谢若老、J哥、师兄、前辈、同学、朋友、陌生人，在我行走在大数据道路上给我的谆谆教诲，同时此博客仅作为学习笔记存在，严禁任何人以何种理由商用，作者QQ: 971118017 | TUNANのBlog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="author-info"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">Tunan</div><div class="author-info__description text-center">BigData Developer</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">129</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">30</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">26</span></a></div></div></div><nav class="no-bg" id="nav"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">TUNANのBlog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="site-info"><div id="site-title">TUNANのBlog</div><div id="site-sub-title">感谢若老、J哥、师兄、前辈、同学、朋友、陌生人，在我行走在大数据道路上给我的谆谆教诲，同时此博客仅作为学习笔记存在，严禁任何人以何种理由商用，作者QQ: 971118017</div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2020/02/17/offlinedw/4.%E9%A1%B9%E7%9B%AE%E6%95%B0%E6%8D%AE%E7%9A%84ETL/">项目数据的ETL</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-02-17</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/OfflineDW/">OfflineDW</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/OfflineDW/">OfflineDW</a></span><div class="content"><p>系统架构图:</p>
<p><img src="https://yerias.github.io/offlinedw/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84%E9%A1%B9%E7%9B%AE%E5%9B%BE_2.jpg" alt="数据仓库架构项目图"></p>
<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ol>
<li><p>为什么要进行ETL</p>
</li>
<li><p>什么是ETL</p>
</li>
<li><p>ETL该怎么做</p>
</li>
<li><p>ETL在服务器上运行需要解决的问题</p>
</li>
</ol>
<h2 id="为什么要进行ETL"><a href="#为什么要进行ETL" class="headerlink" title="为什么要进行ETL"></a>为什么要进行ETL</h2><p>在上一步我们使用Flume采集数据到HDFS，从系统架构图来看现在要进行数据的ETL操作，ETL进程对数据进行规范化、验证、清洗，并最终装载进入数据仓库</p>
<h2 id="什么是ETL"><a href="#什么是ETL" class="headerlink" title="什么是ETL"></a>什么是ETL</h2><p>ETL 即 Extract Transform Load的首字母 ==&gt; 抽取、转换、加载</p>
<h2 id="ETL该怎么做"><a href="#ETL该怎么做" class="headerlink" title="ETL该怎么做"></a>ETL该怎么做</h2><p>数据采集到HDFS上指定的目录下，通过MR写入数据，进行ETL操作，并写出到指定的目录下，ETL操作包括定义数据字段的序列化类，把时间解析出年月日，把URL解析为http、domain和path、对异常值进行处理(try/catch)，使用计数器。</p>
<p>需要注意:</p>
<ol>
<li><p>时间解析参考代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//时间</span></span><br><span class="line">String time = split[<span class="number">0</span>];</span><br><span class="line">SimpleDateFormat format = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"[dd/MM/yyyy:HH:mm:ss +0800]"</span>);</span><br><span class="line">Date date = format.parse(split[<span class="number">0</span>]);</span><br><span class="line"></span><br><span class="line">Calendar calendar = Calendar.getInstance();</span><br><span class="line">calendar.setTime(date);</span><br><span class="line"></span><br><span class="line"><span class="comment">//year</span></span><br><span class="line">String year =String.valueOf(calendar.get(Calendar.YEAR));</span><br><span class="line">access.setYear(year);</span><br><span class="line"></span><br><span class="line"><span class="comment">//month</span></span><br><span class="line"><span class="keyword">int</span>  month = calendar.get(Calendar.MONTH)+<span class="number">1</span>;</span><br><span class="line">access.setMont(month &lt; <span class="number">10</span> ? <span class="string">"0"</span>+month:String.valueOf(month))</span><br><span class="line"></span><br><span class="line"><span class="comment">//day</span></span><br><span class="line"><span class="keyword">int</span> day = calendar.get(Calendar.DAY_OF_MONTH);</span><br><span class="line">access.setDay(day &lt; <span class="number">10</span> ? <span class="string">"0"</span>+day:String.valueOf(day));</span><br></pre></td></tr></table></figure>
</li>
<li><p>异常值是舍去还是保留，这跟try/catch如何操作有关系，参考代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//要数据,设默认值为0</span></span><br><span class="line"><span class="keyword">long</span> responseSize = <span class="number">0L</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    responseSize = Long.parseLong(split[<span class="number">9</span>].trim());</span><br><span class="line">    access.setResponseSize(responseSize);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    access.setResponseSize(responseSize);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 不要数据，产生异常直接返回</span></span><br><span class="line">Long responseSize = Long.parseLong(split[<span class="number">9</span>].trim());</span><br><span class="line">access.setResponseSize(responseSize);</span><br></pre></td></tr></table></figure>
</li>
<li><p>计数器mapper中的参考代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">context.getCounter(<span class="string">"ETL"</span>,<span class="string">"SUCCEED"</span>).increment(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><p>计数器Driver中的参考代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//通过迭代器获取mapper中的计数器</span></span><br><span class="line">CounterGroup group = job.getCounters().getGroup(<span class="string">"ETL"</span>);</span><br><span class="line">Iterator&lt;Counter&gt; iterator = group.iterator();</span><br><span class="line"><span class="keyword">while</span>(iterator.hasNext())&#123;</span><br><span class="line">Counter counter = iterator.next();</span><br><span class="line">     System.out.println(counter.getName() + <span class="string">"==&gt;"</span> + counter.getValue());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意: 这里可以通过jdbc将计数器结果根据批次写到mysql数据库中</p>
</li>
</ol>
<h2 id="ETL在服务器上运行需要解决的问题"><a href="#ETL在服务器上运行需要解决的问题" class="headerlink" title="ETL在服务器上运行需要解决的问题"></a>ETL在服务器上运行需要解决的问题</h2><p>在本地测试好代码后，上传Jar包到服务器上，跑HDFS上的数据</p>
<p>首先创建三个文件夹lib、data、script放ETL相关的文件，运行脚本的shell文件就在script目录下</p>
<p>由于我们把ETL打的瘦包，所以很多数据需要的依赖Jar包得不到，还有ip解析库的数据库也需要上传到本地文件下</p>
<p>思路是:</p>
<ol>
<li><p>把ip解析库放到项目的resources目录下</p>
</li>
<li><p>把需要的依赖上传到lib目录下</p>
</li>
<li><p>在<code>~/.bashrc</code>文件下导入LIBJARS路径用来指向lib目录下的依赖</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">export LIBJARS=/home/hadoop/lib/LIBJARS</span><br><span class="line">export LIBJARS=$LIBJARS/commons-lang3-<span class="number">3.4</span>.jar,$LIBJARS/qqwry.dat,$LIBJARS/mysql-connector-java-<span class="number">5.1</span><span class="number">.27</span>-bin.jar</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行jar包命令写进脚本，执行脚本即可</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">time=<span class="number">20200217</span></span><br><span class="line">hadoop jar hadoop-client-<span class="number">1.0</span><span class="number">.0</span>.jar  com.tunan.ip.ipParseDriver  -libjars $LIBJARS  /item/offline-dw/raw/access/$time /item/offline-dw/tmp/access/$time/</span><br></pre></td></tr></table></figure>

<p><code>-libjars</code>用来指定外部依赖，<code>$LIBJARS</code>指向<code>~/.bashrc</code>文件中的路径</p>
<p><code>/item/offline-dw/raw/access/$time</code>是源数据，这个数据一般保存7天后即可删除</p>
<p><code>/item/offline-dw/tmp/access/$time</code>/是ETL后的数据</p>
<p><code>$LIBJARS/qqwry.dat</code>是ip解析库的路径</p>
</li>
<li><p>还可以把ip解析库在服务器上的路径写死在代码中，就不用手动指定ip解析库的路径了</p>
</li>
</ol>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/02/16/offlinedw/3.%E9%A1%B9%E7%9B%AE%E6%95%B0%E6%8D%AE%E7%9A%84%E9%87%87%E9%9B%86/">项目数据的采集</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-02-16</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/OfflineDW/">OfflineDW</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/OfflineDW/">OfflineDW</a></span><div class="content"><p>系统架构图:</p>
<p><img src="https://yerias.github.io/offlinedw/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84%E9%A1%B9%E7%9B%AE%E5%9B%BE_1.jpg" alt="数据仓库架构项目图"></p>
<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>Flume是用来做什么的</p>
<p>为什么要使用Flume</p>
<p>Flume具体怎么用</p>
<p>java客户端上传消息到Flume写到HDFS</p>
<p>解决Flume采集数据时生成大量小文件的问题</p>
<h2 id="为什么要使用Flume"><a href="#为什么要使用Flume" class="headerlink" title="为什么要使用Flume"></a>为什么要使用Flume</h2><p>在开源框架的选择中，因为Flume is a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of log data. 所以我们选择了Flume作为数据的采集工具</p>
<h2 id="Flume是用来做什么的"><a href="#Flume是用来做什么的" class="headerlink" title="Flume是用来做什么的"></a>Flume是用来做什么的</h2><p>从系统架构图上来看，用户只要产生行为，那么日志就会在Nginx服务器中保存，所以我们现在要做的就是把数据从Nginx服务器中使用Flume采集到HDFS上</p>
<h2 id="Flume具体怎么用"><a href="#Flume具体怎么用" class="headerlink" title="Flume具体怎么用"></a>Flume具体怎么用</h2><h3 id="Flume"><a href="#Flume" class="headerlink" title="Flume"></a>Flume</h3><p>Flume就是一个针对日志数据进行采集和汇总的一个框架</p>
<p>Flume的进程叫做Agent，每个Agent中有Srouce、Channel、Sink</p>
<p>Flume从使用层面来讲就是写配置文件，其实就是配置我们的Agent，只要学会从官网查配置就行了</p>
<p><a href="http://flume.apache.org" target="_blank" rel="noopener">Flume官网</a></p>
<h3 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a>Agent</h3><p>Source中的常用方式有 avro、exec、spooling、taildir、kafka</p>
<p>Channel中的常用方式有 memory、kafka、file</p>
<p>Sink中的常用方式有 hdfs、logger、avro、kafka</p>
<h3 id="示例配置"><a href="#示例配置" class="headerlink" title="示例配置"></a>示例配置</h3><p>它描述了一个单节点Flume部署。该配置允许用户生成事件，然后将它们记录到控制台。以后写配置只需要在这个配置文件的基础上做出选择性的修改即可</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Name the components on this agent</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># Describe/configure the source</span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<p>有了这个配置文件，我们可以按如下方式启动Flume:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">flume-ng agent \</span><br><span class="line">--name a1 \</span><br><span class="line">--conf $FLUME_HOME/conf \</span><br><span class="line">--conf-file $FLUME_HOME/script/example.conf \</span><br><span class="line">-Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

<p>输入端:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">telnet localhost 44444</span><br></pre></td></tr></table></figure>

<h3 id="TAILDIR"><a href="#TAILDIR" class="headerlink" title="TAILDIR"></a>TAILDIR</h3><p>taildir是Source端可以选择的一个类型，它可以同时支持目录和文件，并且支持offset，Flume挂了重启后可以接着上次消费的地方继续消费，下面提供一个配置taildir的文件</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"># Describe/configure the source</span><br><span class="line">a1.sources.r1.type = taildir</span><br><span class="line">a1.sources.r1.positionFile = /home/hadoop/taildir_position.json	#这个目录的上一级目录不能存在</span><br><span class="line">a1.sources.r1.filegroups = f1 f2</span><br><span class="line">a1.sources.r1.filegroups.f1 = /home/hadoop/data/flume/example</span><br><span class="line">a1.sources.r1.headers.f1.headerKey1 = value1</span><br><span class="line">a1.sources.r1.filegroups.f2 = /home/hadoop/data/flume/.*log.*</span><br><span class="line">a1.sources.r1.headers.f2.headerKey1 = value2</span><br><span class="line">a1.sources.r1.headers.f2.headerKey2 = value2-<span class="number">2</span></span><br><span class="line">a1.sources.r1.fileHeader = <span class="keyword">true</span></span><br><span class="line">a1.sources.ri.maxBatchCount = <span class="number">1000</span></span><br></pre></td></tr></table></figure>

<p>其中<code>taildir_position.json</code>文件是用来记录文件读取offset的位置，方便下次继续从offset位置读取</p>
<p>注意<code>taildir_position.json</code>文件不能存在上级目录，不然会报错</p>
<h2 id="java客户端上传消息到Flume写到HDFS"><a href="#java客户端上传消息到Flume写到HDFS" class="headerlink" title="java客户端上传消息到Flume写到HDFS"></a>java客户端上传消息到Flume写到HDFS</h2><p>参考博客: <a href="https://blog.csdn.net/lbship/article/details/85336555" target="_blank" rel="noopener">https://blog.csdn.net/lbship/article/details/85336555</a></p>
<ol>
<li><p>在java客户端编写代码生成logger数据</p>
<p>添加依赖</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">   &lt;groupId&gt;org.apache.flume.flume-ng-clients&lt;/groupId&gt;</span><br><span class="line">   &lt;artifactId&gt;flume-ng-log4jappender&lt;/artifactId&gt;</span><br><span class="line">   &lt;version&gt;1.6.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;org.slf4j&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;</span><br><span class="line">  &lt;version&gt;1.7.21&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;org.apache.flume.flume-ng-clients&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;flume-ng-log4jappender&lt;/artifactId&gt;</span><br><span class="line">  &lt;version&gt;1.6.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>

<p>生产日志</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Logger logger = Logger.getLogger(LoggerGenerator<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>())</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(i&lt;<span class="number">99</span>)&#123;</span><br><span class="line">        Thread.sleep(<span class="number">500</span>);</span><br><span class="line">        logger.info(<span class="string">"now is : "</span>+i);</span><br><span class="line">        i++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在log4j.properties文件中添加代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">log4j.rootCategory=info,console,flume  <span class="comment">//rootCategory需要指定flume</span></span><br><span class="line">    </span><br><span class="line">log4j.appender.flume=org.apache.flume.clients.log4jappender.Log4jAppender</span><br><span class="line">log4j.appender.flume.Hostname=<span class="number">121.196</span><span class="number">.220</span><span class="number">.143</span></span><br><span class="line">log4j.appender.flume.Port=<span class="number">41414</span></span><br><span class="line">log4j.appender.flume.UnsafeMode=<span class="keyword">true</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>在Hostname服务端接收log4j.properties文件中指定的端口即可，注意Source类型需要使用avro(序列化)</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">a1.sources.r1.type = avro</span><br><span class="line">a1.sources.r1.bind = <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line">a1.sources.r1.port = <span class="number">41414</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>写出到HDFS，这里需要注意解决时间戳和乱码问题</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path = /flume/%y-%m-%d/%H%M/%S	#时间需要根据实际情况修改</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = events-</span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp=true		#解决时间戳问题</span><br><span class="line">a1.sinks.k1.hdfs.fileType=DataStream 		#解决乱码</span><br></pre></td></tr></table></figure>

<p>使用<code>useLocalTimeStamp=true</code>参数解决时间戳异常，使用<code>fileType=DataStream</code>解决文件内容乱码问题</p>
</li>
</ol>
<h2 id="解决Flume采集数据时生成大量小文件的问题"><a href="#解决Flume采集数据时生成大量小文件的问题" class="headerlink" title="解决Flume采集数据时生成大量小文件的问题"></a>解决Flume采集数据时生成大量小文件的问题</h2><p>在使用Flume采集数据时，由于默认参数的影响会生产大量小文件，我们先看默认参数</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">hdfs.rollInterval	<span class="number">30</span>	滚动当前文件之前要等待的秒数</span><br><span class="line">hdfs.rollSize	<span class="number">1024</span>	触发滚动当前文件的大小，单位bytes(B)</span><br><span class="line">hdfs.rollCount	<span class="number">10</span>		触发滚动当前文件的events数量</span><br></pre></td></tr></table></figure>

<p>我们看到默认生成文件有三个条件，每30秒、每1M、每10个events，这样的配置会生成大量的小文件，所以我们要对这三个文件进行修改</p>
<p>最终生成的文件必须综合时间、文件大小、event数量来决定，时间太长或者文件太大都不利于最终生成的文件。该时间还需要配合<code>hdfs.path</code>参数指定的生成文件时间。</p>
<p>注意<code>sink.type</code>如果是<code>memory</code>模式，注意文件的大小，防止内存不足，太大可以设置<code>sink.type = file</code></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/02/15/offlinedw/2.%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E7%9A%84%E6%B5%81%E7%A8%8B/">项目开发的流程</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-02-15</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/OfflineDW/">OfflineDW</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/OfflineDW/">OfflineDW</a></span><div class="content"><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ol>
<li>为什么是离线数据仓库</li>
<li>采集什么日志</li>
<li>技术实现流程</li>
</ol>
<h2 id="为什么是离线数据仓库"><a href="#为什么是离线数据仓库" class="headerlink" title="为什么是离线数据仓库"></a>为什么是离线数据仓库</h2><h3 id="什么是数据仓库"><a href="#什么是数据仓库" class="headerlink" title="什么是数据仓库"></a>什么是数据仓库</h3><p>将多个数据源的数据经过ETL之后，按照一定的主题继承，提供 <code>决策支持</code> 和 <code>联机分析应用</code> 的结构化数据环境</p>
<h3 id="为什么要建数据仓库"><a href="#为什么要建数据仓库" class="headerlink" title="为什么要建数据仓库"></a>为什么要建数据仓库</h3><p>摆脱多种不同数据源、异构数据库、不同数据格式等等带来的问题</p>
<h2 id="采集用户行为日志"><a href="#采集用户行为日志" class="headerlink" title="采集用户行为日志"></a>采集用户行为日志</h2><p>既然要建数据仓库，那么第一步需要考虑的是我们的数据从哪里来？来的什么数据？这些数据是做什么的？</p>
<h3 id="数据是从哪里来的？"><a href="#数据是从哪里来的？" class="headerlink" title="数据是从哪里来的？"></a>数据是从哪里来的？</h3><p><code>数据</code>通过<code>采集团队</code>从<code>ngnix</code>服务器(请求携带的数据经过nginx服务器)、<code>埋点日志</code>(用户行为过程及结果的记录)和<code>SDK</code>(软件开发工具包)通过<code>flume</code>采集产生的数据到HDFS上</p>
<h3 id="来的是什么数据？"><a href="#来的是什么数据？" class="headerlink" title="来的是什么数据？"></a>来的是什么数据？</h3><p>采集到的是用户的行为数据，包括日志和业务数据，只要是用户访问、搜索、点击、收藏都会产生数据通过flume采集到了HDFS上</p>
<h3 id="数据可以用来做什么的？"><a href="#数据可以用来做什么的？" class="headerlink" title="数据可以用来做什么的？"></a>数据可以用来做什么的？</h3><p>数据运用在数据仓库中会进行一系列的ETL、调度、建模，最终用来可视化分析。</p>
<h2 id="技术实现流程"><a href="#技术实现流程" class="headerlink" title="技术实现流程"></a>技术实现流程</h2><h3 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h3><p>从输入==&gt;到输出</p>
<p>可以使用的工具:</p>
<ol>
<li>SDK</li>
<li>Flume(推介)</li>
<li>Sqoop</li>
<li>DataX</li>
</ol>
<h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>数据预处理也就是对数据进行ETL/清洗操作</p>
<ol>
<li>格式处理：时间、IP、URL</li>
<li>数据拆分：1 col ==&gt; n cols  (URL、UA)</li>
<li>数据补充：1 col ==&gt; n cols</li>
</ol>
<h3 id="数据入库"><a href="#数据入库" class="headerlink" title="数据入库"></a>数据入库</h3><p>数据清洗后的数据导入到你HIVE中的库/表中(大宽表/N多列)</p>
<ol>
<li>分析的维度：day or hour</li>
<li>表：分区外部表</li>
</ol>
<h3 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h3><p>根据不同业务的执行SQL并且通过SQOOP存到RDBMS/NoSQL的表中</p>
<h3 id="数据展示"><a href="#数据展示" class="headerlink" title="数据展示"></a>数据展示</h3><ol>
<li>WEB ==&gt; RDBMS</li>
<li>Echarts</li>
<li>d3</li>
<li>HUE</li>
<li>Zeppelin</li>
</ol>
<h3 id="项目架构"><a href="#项目架构" class="headerlink" title="项目架构"></a>项目架构</h3><p><img src="https://yerias.github.io/offlinedw/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84%E9%A1%B9%E7%9B%AE%E5%9B%BE.jpg" alt="数据仓库架构项目图"></p>
<h3 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h3><ol>
<li><p>评估你这个业务线需要多少资源，数据量的计算: 一条数据的大小==&gt;*用户数*每个人一天产生的数据量==&gt;*副本数*天数(365)==&gt;*每年30%的上升空间</p>
</li>
<li><p>每个节点磁盘多少？内存多少？物理核多少？通过计算得出需要的节点数</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">core：<span class="number">32</span>/<span class="number">64</span> 决定了应用程序的快慢</span><br><span class="line">memory：<span class="number">256</span>/<span class="number">512</span> 决定了应用程序的生死</span><br><span class="line">disk：<span class="number">10</span>T*数量</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h2><p>对数据进行ETL操作时，N个业务：至少是3*N个SQL(3层)，并且尽可能把一些麻烦的/繁琐的/join等SQL操作提前进行</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/02/14/offlinedw/1.%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E7%9A%84%E5%87%86%E5%A4%87/">项目开发的准备</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-02-14</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/OfflineDW/">OfflineDW</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Flume/">Flume</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/OfflineDW/">OfflineDW</a></span><div class="content"><hr>
<p>涉及到具体的文档，这里只描述流程</p>
<hr>
<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ol>
<li><p>项目调研</p>
</li>
<li><p>需求分析</p>
</li>
<li><p>方案设计</p>
</li>
</ol>
<h2 id="项目调研"><a href="#项目调研" class="headerlink" title="项目调研"></a>项目调研</h2><p>是什么行业? </p>
<p>关于什么业务？</p>
<p>调研人员(资深的产品经理/业务分析人员)</p>
<h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><p>要做什么?</p>
<p>做成啥样?</p>
<ol>
<li>需求(表层的需求、隐藏的需求、售前团队的需求)</li>
<li>产出(需求规格说明书、进度规划：甘特图)</li>
<li>人员(项目经理、产品、leader)</li>
</ol>
<h2 id="方案设计"><a href="#方案设计" class="headerlink" title="方案设计"></a>方案设计</h2><h3 id="概要设计"><a href="#概要设计" class="headerlink" title="概要设计"></a>概要设计</h3><ol>
<li>技术架构(框架的调研、”糙”点的测试报告)</li>
<li>模块</li>
<li>功能点</li>
<li>和甲方确认过程</li>
</ol>
<h3 id="详细设计"><a href="#详细设计" class="headerlink" title="详细设计"></a>详细设计</h3><p>详细设计是最复杂的、篇幅最大的，针对具体功能的实现</p>
<p>基本要求(类、方法(入参、出参)、UML、图表)</p>
<p>系统要求/非功能需求</p>
<ol>
<li>扩展性</li>
<li>容错性</li>
<li>是否支持定制化：Azkaban</li>
<li>监控/告警(发生后)/预警(发生前)</li>
</ol>
<h3 id="功能开发"><a href="#功能开发" class="headerlink" title="功能开发"></a>功能开发</h3><p>码农对着文档把方法实现了而已，CICD(持续集成(CI)、持续交付(CD))</p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><ol>
<li>测试覆盖率 95%</li>
<li>场景测试(案例)</li>
<li>功能测试</li>
<li>联调测试(一个完整流程)</li>
<li>性能/压力测试</li>
<li>用户测试</li>
</ol>
<h3 id="部署上线"><a href="#部署上线" class="headerlink" title="部署上线"></a>部署上线</h3><ol>
<li>试运行(“双活”系统做DIFF)</li>
<li>正式上线</li>
</ol>
<h3 id="后期维护"><a href="#后期维护" class="headerlink" title="后期维护"></a>后期维护</h3><p>后期维护的费用并不低，包括开发新功能，修复老bug</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/04/09/cdh/9/">CentOS7安装CDH 第九章：CDH中安装Kafka</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-04-09</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/CDH/">CDH</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/CDH/">CDH</a></span><div class="content"><h2 id="CDH官网Kafka的安装教程网址"><a href="#CDH官网Kafka的安装教程网址" class="headerlink" title="CDH官网Kafka的安装教程网址"></a>CDH官网Kafka的安装教程网址</h2><p><a href="https://www.cloudera.com/documentation/kafka/latest/topics/kafka_installing.html#concept_m2t_d45_4r" target="_blank" rel="noopener">点击进入官网</a></p>
<p><img src="https://yerias.github.io/cdh/kafka-1.png" alt=""></p>
<h2 id="下载对应的Kafka版本"><a href="#下载对应的Kafka版本" class="headerlink" title="下载对应的Kafka版本"></a>下载对应的Kafka版本</h2><ol>
<li><p>查看CDH和Kafka的版本对应列表：</p>
<p><a href="https://www.cloudera.com/documentation/enterprise/release-notes/topics/rn_consolidated_pcm.html#pcm_kafka" target="_blank" rel="noopener">点击进入官网</a></p>
</li>
</ol>
<p><img src="https://yerias.github.io/cdh/kafka-2.png" alt=""></p>
<ol start="2">
<li><p>因为安装的CDH版本为5.10或5.12，故选择的Kafka版本为2.2.x和0.10.2，此时去网站找到对应的Kafka版本：</p>
<p><a href="https://www.cloudera.com/documentation/kafka/latest/topics/kafka_packaging.html#concept_fzg_phl_br" target="_blank" rel="noopener">点击进入官网</a></p>
</li>
</ol>
<p><img src="https://yerias.github.io/cdh/kafka-3.png" alt=""></p>
<ol start="3">
<li>点击对应的下载地址，下载该Kafka的parcel包（需更改sha1的后缀名）：</li>
</ol>
<p><img src="https://yerias.github.io/cdh/kafka-4.png" alt=""></p>
<ol start="4">
<li>最终的主节点上的kafka_parcel包(包的位置任意，最终都要移动到/var/www/html/kafka_parcel目录下)</li>
</ol>
<p><img src="https://yerias.github.io/cdh/kafka-4-2.jpg" alt=""></p>
<h2 id="安装Kafka服务"><a href="#安装Kafka服务" class="headerlink" title="安装Kafka服务"></a>安装Kafka服务</h2><ol>
<li><p>将主节点上Kafka的parcel包（3个文件）上传到/var/www/html/kafka_parcel目录下，需配置好https服务，请参考上述CDH安装时的方法配置，在浏览器上能访问到如下场景即可：</p>
<p>安装httpd: <code>yum install -y httpd</code></p>
</li>
</ol>
<p><img src="https://yerias.github.io/cdh/kafka-5.png" alt=""></p>
<ol start="2">
<li>点击CDH主页面中的主机下面的Parcel按钮：</li>
</ol>
<p><img src="https://yerias.github.io/cdh/kafka-6.png" alt=""></p>
<ol start="3">
<li>点击Parcel界面的配置按钮，配置Kafka的地址，该地址默认是官网地址，但在CDH的离线安装时已将所有的在线地址删除，所以在这加上Kafka的Parcel包的离线地址即可：</li>
</ol>
<p><img src="https://yerias.github.io/cdh/kafka-7.png" alt=""></p>
<ol start="4">
<li>在Parcel界面，点击Kafka的下载按钮：</li>
</ol>
<p><img src="https://yerias.github.io/cdh/kafka-8.png" alt=""></p>
<ol start="5">
<li>依次执行Kafka的分配和激活：</li>
</ol>
<p><img src="https://yerias.github.io/cdh/kafka-9.png" alt=""></p>
<p><img src="https://yerias.github.io/cdh/kafka-9-2.png" alt="kafka-9-2"></p>
<h2 id="将Kafka服务添加到CDH中"><a href="#将Kafka服务添加到CDH中" class="headerlink" title="将Kafka服务添加到CDH中"></a>将Kafka服务添加到CDH中</h2><ol>
<li>在CDH的主界面点击添加服务按钮，并选择Kafka服务：</li>
</ol>
<p><img src="https://yerias.github.io/cdh/kafka-10.png" alt=""></p>
<ol start="2">
<li>给Kafka分配节点（Kafka后面2个服务一般情况下不选）：</li>
</ol>
<p><img src="https://yerias.github.io/cdh/kafka-11.png" alt=""></p>
<p><img src="https://yerias.github.io/cdh/kafka-11-2.png" alt=""></p>
<ol start="3">
<li>Kafka的配置文件进行配置：</li>
</ol>
<p>配置Kafka的文件存放目录，因为Kafka是依赖Zookeeper的，所以Kafka的文件也是存放在Zookeeper的目录中，如果要卸载Kafka时，需要将这些Kafka的文件也删除，所以可以把Kafka的文件存放在一个目录中：</p>
<p>Kafka的文件存放目录：</p>
<p><img src="https://yerias.github.io/cdh/kafka-12.png" alt=""></p>
<p>进入Zookeeper的文件管理界面（命令行）：</p>
<p><img src="https://yerias.github.io/cdh/kafka-13.png" alt=""></p>
<p><img src="https://yerias.github.io/cdh/kafka-14.png" alt=""></p>
<p>因为Kafka是一个消息中间键，有将生产者生产的信息进行缓存的操作，所以在配置Kafka的数据存储目录时需要注意，将数据存放到一个比较大的磁盘中，该数据存放的目录如下配置所示：</p>
<p><img src="https://yerias.github.io/cdh/kafka-15.png" alt=""></p>
<p>在卸载重装Kafka时，需要将Zookeeper目录下的Kafka文件，以及Kafka数据存放的目录都清空，请注意是每个节点都要清空，否则不能重装。</p>
<ol start="5">
<li>启动Kafka服务，会发现Kafka服务不能成功启动，报错如下：</li>
</ol>
<p><img src="https://yerias.github.io/cdh/kafka-16.png" alt=""></p>
<p>查看日志</p>
<p><img src="https://yerias.github.io/cdh/kafka-17.png" alt=""></p>
<p>此时为主机的内存不足，返回Kafka配置文件界面，修改memory中的Java Heap Size of Broker值为512M（如果机器内存充足，可以再大一些），如下：</p>
<p><img src="https://yerias.github.io/cdh/kafka-18.png" alt=""></p>
<p>修改之后去CDH的主界面重启Kafka，启动成功，如下所示：</p>
<p><img src="https://yerias.github.io/cdh/kafka-19.png" alt=""></p>
<h2 id="测试Kafka"><a href="#测试Kafka" class="headerlink" title="测试Kafka"></a>测试Kafka</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建topic</span></span><br><span class="line">./kafka-topics.sh \</span><br><span class="line">--create \</span><br><span class="line">--zookeeper cdh001:2181,cdh002:2181,cdh003:2181/kafka \</span><br><span class="line">--replication-factor 2 --partitions 3 --topic cloudera</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动生产者</span></span><br><span class="line">./kafka-console-producer.sh \</span><br><span class="line">--broker-list cdh001:9092 ,cdh002:9092 ,cdh003:9092  \</span><br><span class="line">--topic cloudera</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动消费者</span></span><br><span class="line">./kafka-console-consumer.sh \</span><br><span class="line">--bootstrap-server cdh001:9092 ,cdh002:9092 ,cdh003:9092  \</span><br><span class="line">--from-beginning \</span><br><span class="line">--topic cloudera</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除topic</span></span><br><span class="line">./kafka-topics.sh  \</span><br><span class="line">--delete \</span><br><span class="line">--zookeeper  cdh001:2181,cdh002:2181,cdh003:2181/kafka  \</span><br><span class="line">--topic cloudera</span><br></pre></td></tr></table></figure>

<h2 id="重装Kafka"><a href="#重装Kafka" class="headerlink" title="重装Kafka"></a>重装Kafka</h2><p>除了上文提到的要删除zookeeper中的kafka目录，还要删除Kafka的数据存储目录，即<code>/var/local/kafka/data</code></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/02/01/git/1/">GIT的常用操作&amp;GITHUB的常用操作&amp;在IDEA中使用GIT操作GITHUB</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-02-01</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Git/">Git</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Git/">Git</a></span><div class="content"><h2 id="GIT实战操作"><a href="#GIT实战操作" class="headerlink" title="GIT实战操作"></a>GIT实战操作</h2><ol>
<li><p>创建版本库</p>
<p>在项目文件夹内，执行: git init</p>
</li>
<li><p>提交文件</p>
<p>新建文件后，通过git status 进行查看文件状态(可选)</p>
<p>将文件添加到暂存区  git add 文件名</p>
<p>或者也可以git commit –m “注释内容”, 直接带注释提交</p>
</li>
<li><p>查看文件提交记录</p>
<p>git log –pretty=oneline 文件名   进行查看历史记录</p>
</li>
<li><p>回退历史</p>
<p>git reset –hard HEAD~n 回退n次操作</p>
</li>
<li><p>版本穿越</p>
<p>进行查看历史记录的版本号，执行 git reflog 文件名</p>
<p>执行 git reset –hard 版本号</p>
</li>
<li><p>还原文件</p>
<p>git checkout – 文件名 </p>
</li>
<li><p>删除某个文件</p>
<p>先删除文件 git rm 文件名</p>
<p>再git add 再提交</p>
</li>
<li><p>创建分支</p>
<p>git branch &lt;分支名&gt;</p>
<p>git branch –v 查看分支</p>
</li>
<li><p>切换分支</p>
<p>git checkout –b &lt;分支名&gt;</p>
</li>
<li><p>合并分支</p>
<p>先切换到主干  git checkout master</p>
<p>git merge &lt;分支名&gt;</p>
</li>
<li><p>合并时冲突</p>
<p>程序合并时发生冲突系统会提示CONFLICT关键字，命令行后缀会进入MERGING状态，表示此时是解决冲突的状态。</p>
<p>然后修改冲突文件的内容，再次git add <file> 和git commit 提交后，后缀MERGING消失，说明冲突解决完成。</p>
</li>
</ol>
<h2 id="GITHUB实战操作"><a href="#GITHUB实战操作" class="headerlink" title="GITHUB实战操作"></a>GITHUB实战操作</h2><ol>
<li><p>搭建代码库</p>
<ul>
<li><p>git init</p>
</li>
<li><p>git config </p>
<ul>
<li>git config –global(全局) user.email “<a href="mailto:you@example.com" target="_blank" rel="noopener">you@example.com</a>”</li>
<li>git config –global(全局) user.name “Your Name”</li>
</ul>
</li>
</ul>
</li>
<li><p>提交代码到本地仓库</p>
<ul>
<li><p>git add 文件名</p>
</li>
<li><p>git commit –m “注释内容”</p>
</li>
</ul>
</li>
<li><p>GitHub准备工作：</p>
<ul>
<li><p>注册GitHub账号</p>
</li>
<li><p>在GitHub搭建项目</p>
</li>
</ul>
</li>
<li><p>推送代码到远端</p>
<ul>
<li><p>git remote add origin <url>(仓库地址)</p>
</li>
<li><p>git push origin master</p>
</li>
</ul>
</li>
<li><p>其他用户克隆</p>
<p>git clone <url></p>
</li>
<li><p>其他用户提交代码到本地仓库</p>
<ul>
<li><p>git add 文件名</p>
</li>
<li><p>git commit –m “注释内容”</p>
</li>
</ul>
</li>
<li><p>其他用户推送到远端仓库</p>
<ul>
<li>git push origin master</li>
</ul>
</li>
<li><p>其他用户拉取代码</p>
<ul>
<li>git pull origin master</li>
</ul>
</li>
<li><p>增加远程地址</p>
<ul>
<li>git remote add &lt;远端代号(origin)&gt;  &lt;远端地址&gt;</li>
</ul>
</li>
<li><p>推送到远程库</p>
<ul>
<li>git push  &lt;远端代号&gt;  &lt;本地分支名称&gt;</li>
</ul>
</li>
<li><p>合作开发权限</p>
<p><img src="https://yerias.github.io/git/%E6%B7%BB%E5%8A%A0%E5%90%88%E4%BD%9C%E4%BC%99%E4%BC%B41.jpg" alt="添加合作伙伴1"></p>
<p><img src="https://yerias.github.io/git/%E6%B7%BB%E5%8A%A0%E5%90%88%E4%BD%9C%E4%BC%99%E4%BC%B42.jpg" alt="添加合作伙伴2"></p>
</li>
<li><p>协作冲突</p>
<p>在上传或同步代码时，由于你和他人都改了同一文件的同一位置的代码，版本管理软件无法判断究竟以谁为准，就会报告冲突,需要程序员手工解决。</p>
<ul>
<li><p>修改合并</p>
</li>
<li><p>git add 文件名</p>
</li>
<li><p>git commit –m “注释内容”</p>
</li>
<li><p>git push origin master</p>
</li>
</ul>
</li>
</ol>
<h2 id="在IDEA中使用GIT"><a href="#在IDEA中使用GIT" class="headerlink" title="在IDEA中使用GIT"></a>在IDEA中使用GIT</h2><ol>
<li><p>配置</p>
<p>setting配置GIT</p>
<p><img src="https://yerias.github.io/git/%E9%85%8D%E7%BD%AEgit%E6%89%A7%E8%A1%8C%E7%A8%8B%E5%BA%8F.jpg" alt="配置git执行程序"></p>
</li>
<li><p>创建仓库</p>
<p>VCS配置账户密码创建仓库</p>
<p><img src="https://yerias.github.io/git/%E5%88%9B%E5%BB%BAgithub%E4%BB%93%E5%BA%93.jpg" alt="创建github仓库"></p>
</li>
<li><p>提交代码</p>
<p><img src="https://yerias.github.io/git/%E6%8F%90%E4%BA%A4%E4%BB%A3%E7%A0%811.jpg" alt="提交代码1"></p>
<p><img src="https://yerias.github.io/git/%E6%8F%90%E4%BA%A4%E4%BB%A3%E7%A0%812.jpg" alt="提交代码2"></p>
<p><img src="https://yerias.github.io/git/%E6%8F%90%E4%BA%A4%E4%BB%A3%E7%A0%813.jpg" alt="提交代码3"></p>
</li>
<li><p>同步代码</p>
<p><img src="https://yerias.github.io/git/%E5%90%8C%E6%AD%A5%E4%BB%A3%E7%A0%81.jpg" alt="同步代码"></p>
</li>
<li><p>克隆项目</p>
<p><img src="https://yerias.github.io/git/%E5%85%8B%E9%9A%86%E4%BB%A3%E7%A0%811.jpg" alt="克隆代码1"></p>
<p><img src="https://yerias.github.io/git/%E5%85%8B%E9%9A%86%E4%BB%A3%E7%A0%812.jpg" alt="克隆代码2"></p>
</li>
<li><p>解决版本冲突</p>
<p>代码添加到公共区间再次提交</p>
<p><img src="https://yerias.github.io/git/%E7%89%88%E6%9C%AC%E5%86%B2%E7%AA%81.jpg" alt="版本冲突"></p>
</li>
</ol>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/01/08/java/8/">IO流&amp;比较器&amp;内部类&amp;Random</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-01-08</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Java/">Java</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Java/">Java</a></span><div class="content"><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ol>
<li>IO流</li>
<li>比较器</li>
<li>内部类</li>
<li>Random</li>
</ol>
<h2 id="IO流"><a href="#IO流" class="headerlink" title="IO流"></a>IO流</h2><p>Java中的流根据传输方向分为输入输出流，根据操作数据的不同又可以分为字节流和字符流</p>
<h3 id="字节流"><a href="#字节流" class="headerlink" title="字节流"></a>字节流</h3><p>所有的字节流都继承自InputStream接口和OutputStream接口</p>
<p>用于文件传输的是FileInputStream类和FileOutputStream类，传输的是字节，使用FileInputStream读取文件时，可以使用byte字节数组建立一个字节数组缓冲区，读取数据时read方法中传入一个字节数组，每次读取一个字节数组的数据，即可实现缓冲区读取数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">byte</span>[] buff = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">in.read(buff)  <span class="comment">//数据读进buff中</span></span><br><span class="line">out.write(buff) <span class="comment">//write中传入buff写出数据</span></span><br></pre></td></tr></table></figure>

<p>在字节流的IO包中提供了两个带缓冲的字节流，分别是BufferedInputStream和BufferedOutputStream，他们的构造方法中分别接受InputStream和OutputStream，类型的参数作为对象，这两</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> InputStream(filePath));</span><br></pre></td></tr></table></figure>

<h3 id="字符流"><a href="#字符流" class="headerlink" title="字符流"></a>字符流</h3><h2 id="比较器"><a href="#比较器" class="headerlink" title="比较器"></a>比较器</h2><h2 id="内部类"><a href="#内部类" class="headerlink" title="内部类"></a>内部类</h2><h2 id="Random"><a href="#Random" class="headerlink" title="Random"></a>Random</h2></div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/01/05/java/6/">JAVA.UTIL包下的TreeSet和迭代器快速失败的的源码解析以及多线程下故障现象、导致原因、以及解决办法和优化建议</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-01-05</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Java/">Java</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Java/">Java</a></span><div class="content"><hr>
<p>该篇博客不适合小白，只做针对性的api源码解析，以及适合我自身的案例研究</p>
<hr>
<ol>
<li><p>使用多个线程往<code>ArrayList</code>中添加元素</p>
</li>
<li><p>故障现象</p>
</li>
<li><p>故障原因</p>
</li>
<li><p>解决方法</p>
</li>
</ol>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/01/04/java/4/">HashMap多线程问题</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-01-04</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Java/">Java</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Java/">Java</a></span><div class="content"><hr>
<p>该篇博客不适合小白，只做针对性的api源码解析，以及适合我自身的案例研究</p>
<h2 id="jdk1-7中的HashMap"><a href="#jdk1-7中的HashMap" class="headerlink" title="jdk1.7中的HashMap"></a>jdk1.7中的HashMap</h2><p>在jdk1.8中对HashMap做了很多优化，这里先分析在jdk1.7中的问题，相信大家都知道在jdk1.7多线程环境下HashMap容易出现死循环，这里我们先用代码来模拟出现死循环的情况：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="number">1</span> <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashMapTest</span> </span>&#123;</span><br><span class="line"> <span class="number">2</span></span><br><span class="line"> <span class="number">3</span>     <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"> <span class="number">4</span>         HashMapThread thread0 = <span class="keyword">new</span> HashMapThread();</span><br><span class="line"> <span class="number">5</span>         HashMapThread thread1 = <span class="keyword">new</span> HashMapThread();</span><br><span class="line"> <span class="number">6</span>         HashMapThread thread2 = <span class="keyword">new</span> HashMapThread();</span><br><span class="line"> <span class="number">7</span>         HashMapThread thread3 = <span class="keyword">new</span> HashMapThread();</span><br><span class="line"> <span class="number">8</span>         HashMapThread thread4 = <span class="keyword">new</span> HashMapThread();</span><br><span class="line"> <span class="number">9</span>         thread0.start();</span><br><span class="line"><span class="number">10</span>         thread1.start();</span><br><span class="line"><span class="number">11</span>         thread2.start();</span><br><span class="line"><span class="number">12</span>         thread3.start();</span><br><span class="line"><span class="number">13</span>         thread4.start();</span><br><span class="line"><span class="number">14</span>     &#125;</span><br><span class="line"><span class="number">15</span> &#125;</span><br><span class="line"><span class="number">16</span></span><br><span class="line"><span class="number">17</span> <span class="class"><span class="keyword">class</span> <span class="title">HashMapThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line"><span class="number">18</span>     <span class="keyword">private</span> <span class="keyword">static</span> AtomicInteger ai = <span class="keyword">new</span> AtomicInteger();</span><br><span class="line"><span class="number">19</span>     <span class="keyword">private</span> <span class="keyword">static</span> Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"><span class="number">20</span></span><br><span class="line"><span class="number">21</span>     <span class="meta">@Override</span></span><br><span class="line"><span class="number">22</span>     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="number">23</span>         <span class="keyword">while</span> (ai.get() &lt; <span class="number">1000000</span>) &#123;</span><br><span class="line"><span class="number">24</span>             map.put(ai.get(), ai.get());</span><br><span class="line"><span class="number">25</span>             ai.incrementAndGet();</span><br><span class="line"><span class="number">26</span>         &#125;</span><br><span class="line"><span class="number">27</span>     &#125;</span><br><span class="line"><span class="number">28</span> &#125;</span><br></pre></td></tr></table></figure>

<p>上述代码比较简单，就是开多个线程不断进行put操作，并且HashMap与AtomicInteger都是全局共享的。在多运行几次该代码后，出现如下死循环情形：</p>
<p><img src="https://yerias.github.io/java_img/hashmap_1.jpg" alt=""></p>
<p>其中有几次还会出现数组越界的情况：</p>
<p><img src="https://yerias.github.io/java_img/hashmap_2.jpg" alt=""></p>
<p>这里我们着重分析为什么会出现死循环的情况，通过jps和jstack命名查看死循环情况，结果如下：</p>
<p><img src="https://yerias.github.io/java_img/hashmap_3.jpg" alt=""></p>
<p>从堆栈信息中可以看到出现死循环的位置，通过该信息可明确知道死循环发生在HashMap的扩容函数中，根源在<strong>transfer函数</strong>中，jdk1.7中HashMap的transfer函数如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="number">1</span>    <span class="function"><span class="keyword">void</span> <span class="title">transfer</span><span class="params">(Entry[] newTable, <span class="keyword">boolean</span> rehash)</span> </span>&#123;</span><br><span class="line"> <span class="number">2</span>         <span class="keyword">int</span> newCapacity = newTable.length;</span><br><span class="line"> <span class="number">3</span>         <span class="keyword">for</span> (Entry&lt;K,V&gt; e : table) &#123;</span><br><span class="line"> <span class="number">4</span>             <span class="keyword">while</span>(<span class="keyword">null</span> != e) &#123;</span><br><span class="line"> <span class="number">5</span>                 Entry&lt;K,V&gt; next = e.next;</span><br><span class="line"> <span class="number">6</span>                 <span class="keyword">if</span> (rehash) &#123;</span><br><span class="line"> <span class="number">7</span>                     e.hash = <span class="keyword">null</span> == e.key ? <span class="number">0</span> : hash(e.key);</span><br><span class="line"> <span class="number">8</span>                 &#125;</span><br><span class="line"> <span class="number">9</span>                 <span class="keyword">int</span> i = indexFor(e.hash, newCapacity);</span><br><span class="line"><span class="number">10</span>                 e.next = newTable[i];</span><br><span class="line"><span class="number">11</span>                 newTable[i] = e;</span><br><span class="line"><span class="number">12</span>                 e = next;</span><br><span class="line"><span class="number">13</span>             &#125;</span><br><span class="line"><span class="number">14</span>         &#125;</span><br><span class="line"><span class="number">15</span>     &#125;</span><br></pre></td></tr></table></figure>

<p>总结下该函数的主要作用：</p>
<p>在对table进行扩容到newTable后，需要将原来数据转移到newTable中，注意10-12行代码，这里可以看出在转移元素的过程中，使用的是头插法，也就是<strong>链表的顺序会翻转</strong>，这里也是形成死循环的关键点。下面进行详细分析。</p>
<h2 id="扩容造成死循环分析过程"><a href="#扩容造成死循环分析过程" class="headerlink" title="扩容造成死循环分析过程"></a>扩容造成死循环分析过程</h2><p>这里假设</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">#1.hash算法为简单的用key mod链表的大小。</span><br><span class="line"></span><br><span class="line">#2.最开始hash表size=2，key=3,7,5，则都在table[1]中。</span><br><span class="line"></span><br><span class="line">#3.然后进行resize，使size变成4。</span><br></pre></td></tr></table></figure>

<p>未resize前的数据结构如下：</p>
<p><img src="https://yerias.github.io/java_img/hashmap_4.jpg" alt=""></p>
<p>如果在单线程环境下，最后的结果如下：</p>
<p><img src="https://yerias.github.io/java_img/hashmap_5.jpg" alt=""></p>
<p>这里的转移过程，不再进行详述，只要理解transfer函数在做什么，其转移过程以及如何对链表进行反转应该不难。</p>
<p>然后在多线程环境下，假设有两个线程A和B都在进行put操作。线程A在执行到transfer函数中第11行代码处挂起，因为该函数在这里分析的地位非常重要，因此再次贴出来。</p>
<p><img src="https://yerias.github.io/java_img/hashmap_6.jpg" alt=""></p>
<p>此时线程A中运行结果如下：</p>
<p><img src="https://yerias.github.io/java_img/hashmap_7.jpg" alt=""></p>
<p>线程A挂起后，此时线程B正常执行，并完成resize操作，结果如下：</p>
<p><img src="https://yerias.github.io/java_img/hashmap_8.jpg" alt=""></p>
<p><strong>这里需要特别注意的点：由于线程B已经执行完毕，根据Java内存模型，现在newTable和table中的Entry都是主存中最新值：7.next=3，3.next=null。</strong></p>
<p>此时切换到线程A上，在线程A挂起时内存中值如下：e=3，next=7，newTable[3]=null，代码执行过程如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">newTable[<span class="number">3</span>]=e ----&gt; newTable[<span class="number">3</span>]=<span class="number">3</span></span><br><span class="line">e=next ----&gt; e=<span class="number">7</span></span><br></pre></td></tr></table></figure>

<p>此时结果如下：</p>
<p><img src="https://yerias.github.io/java_img/hashmap_9.jpg" alt=""></p>
<p>继续循环：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">e=<span class="number">7</span></span><br><span class="line">next=e.next ----&gt; next=<span class="number">3</span>【从主存中取值】</span><br><span class="line">e.next=newTable[<span class="number">3</span>] ----&gt; e.next=<span class="number">3</span>【从主存中取值】</span><br><span class="line">newTable[<span class="number">3</span>]=e ----&gt; newTable[<span class="number">3</span>]=<span class="number">7</span></span><br><span class="line">e=next ----&gt; e=<span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>结果如下：</p>
<p><img src="https://yerias.github.io/java_img/hashmap_10.jpg" alt=""></p>
<p>再次进行循环：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">e=<span class="number">3</span></span><br><span class="line">next=e.next ----&gt; next=<span class="keyword">null</span></span><br><span class="line">e.next=newTable[<span class="number">3</span>] ----&gt; e.next=<span class="number">7</span> 即：<span class="number">3</span>.next=<span class="number">7</span></span><br><span class="line">newTable[<span class="number">3</span>]=e ----&gt; newTable[<span class="number">3</span>]=<span class="number">3</span></span><br><span class="line">e=next ----&gt; e=<span class="keyword">null</span></span><br></pre></td></tr></table></figure>

<p>注意此次循环：e.next=7，而在上次循环中7.next=3，出现环形链表，并且此时e=null循环结束。</p>
<p>结果如下：</p>
<p><img src="https://yerias.github.io/java_img/hashmap_11.jpg" alt=""></p>
<p>在后续操作中只要涉及轮询hashmap的数据结构，就会在这里发生死循环，造成悲剧。</p>
<h2 id="扩容造成数据丢失分析过程"><a href="#扩容造成数据丢失分析过程" class="headerlink" title="扩容造成数据丢失分析过程"></a>扩容造成数据丢失分析过程</h2><p>遵照上述分析过程，初始时：</p>
<p><img src="https://yerias.github.io/java_img/hashmap_12.jpg" alt=""></p>
<p>线程A和线程B进行put操作，同样线程A挂起：</p>
<p><img src="https://yerias.github.io/java_img/hashmap_13.jpg" alt=""></p>
<p>此时线程A的运行结果如下：</p>
<p><img src="https://yerias.github.io/java_img/hashmap_14.jpg" alt=""></p>
<p>此时线程B已获得CPU时间片，并完成resize操作：</p>
<p><img src="https://yerias.github.io/java_img/hashmap_15.jpg" alt=""></p>
<p>同样注意由于线程B执行完成，newTable和table都为最新值：<strong>5.next=null</strong>。</p>
<p>此时切换到线程A，在线程A挂起时：<strong>e=7，next=5，newTable[3]=null。</strong></p>
<p>执行newtable[i]=e，就将<strong>7放在了table[3]</strong>的位置，此时next=5。接着进行下一次循环：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">e=<span class="number">5</span></span><br><span class="line">next=e.next ----&gt; next=<span class="keyword">null</span>，从主存中取值</span><br><span class="line">e.next=newTable[<span class="number">1</span>] ----&gt; e.next=<span class="number">5</span>，从主存中取值</span><br><span class="line">newTable[<span class="number">1</span>]=e ----&gt; newTable[<span class="number">1</span>]=<span class="number">5</span></span><br><span class="line">e=next ----&gt; e=<span class="keyword">null</span></span><br></pre></td></tr></table></figure>

<p>将5放置在table[1]位置，此时e=null循环结束，<strong>3元素丢失</strong>，并形成<strong>环形链表</strong>。并在后续操作hashmap时造成死循环。</p>
<p><img src="https://yerias.github.io/java_img/hashmap_16.jpg" alt=""></p>
<h2 id="jdk1-8中HashMap"><a href="#jdk1-8中HashMap" class="headerlink" title="jdk1.8中HashMap"></a>jdk1.8中HashMap</h2><p>在jdk1.8中对HashMap进行了优化，在发生hash碰撞，不再采用头插法方式，而是直接插入链表尾部，因此不会出现环形链表的情况，但是在多线程的情况下仍然不安全，这里我们看jdk1.8中HashMap的put操作源码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>  <span class="function"><span class="keyword">final</span> V <span class="title">putVal</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, <span class="keyword">boolean</span> onlyIfAbsent,</span></span></span><br><span class="line"><span class="function"><span class="params"> <span class="number">2</span>                    <span class="keyword">boolean</span> evict)</span> </span>&#123;</span><br><span class="line"> <span class="number">3</span>         Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; <span class="keyword">int</span> n, i;</span><br><span class="line"> <span class="number">4</span>         <span class="keyword">if</span> ((tab = table) == <span class="keyword">null</span> || (n = tab.length) == <span class="number">0</span>)</span><br><span class="line"> <span class="number">5</span>             n = (tab = resize()).length;</span><br><span class="line"> <span class="number">6</span>         <span class="keyword">if</span> ((p = tab[i = (n - <span class="number">1</span>) &amp; hash]) == <span class="keyword">null</span>) <span class="comment">// 如果没有hash碰撞则直接插入元素</span></span><br><span class="line"> <span class="number">7</span>             tab[i] = newNode(hash, key, value, <span class="keyword">null</span>);</span><br><span class="line"> <span class="number">8</span>         <span class="keyword">else</span> &#123;</span><br><span class="line"> <span class="number">9</span>             Node&lt;K,V&gt; e; K k;</span><br><span class="line"><span class="number">10</span>             <span class="keyword">if</span> (p.hash == hash &amp;&amp;</span><br><span class="line"><span class="number">11</span>                 ((k = p.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line"><span class="number">12</span>                 e = p;</span><br><span class="line"><span class="number">13</span>             <span class="keyword">else</span> <span class="keyword">if</span> (p <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line"><span class="number">14</span>                 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(<span class="keyword">this</span>, tab, hash, key, value);</span><br><span class="line"><span class="number">15</span>             <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="number">16</span>                 <span class="keyword">for</span> (<span class="keyword">int</span> binCount = <span class="number">0</span>; ; ++binCount) &#123;</span><br><span class="line"><span class="number">17</span>                     <span class="keyword">if</span> ((e = p.next) == <span class="keyword">null</span>) &#123;</span><br><span class="line"><span class="number">18</span>                         p.next = newNode(hash, key, value, <span class="keyword">null</span>);</span><br><span class="line"><span class="number">19</span>                         <span class="keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD - <span class="number">1</span>) <span class="comment">// -1 for 1st</span></span><br><span class="line"><span class="number">20</span>                             treeifyBin(tab, hash);</span><br><span class="line"><span class="number">21</span>                         <span class="keyword">break</span>;</span><br><span class="line"><span class="number">22</span>                     &#125;</span><br><span class="line"><span class="number">23</span>                     <span class="keyword">if</span> (e.hash == hash &amp;&amp;</span><br><span class="line"><span class="number">24</span>                         ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line"><span class="number">25</span>                         <span class="keyword">break</span>;</span><br><span class="line"><span class="number">26</span>                     p = e;</span><br><span class="line"><span class="number">27</span>                 &#125;</span><br><span class="line"><span class="number">28</span>             &#125;</span><br><span class="line"><span class="number">29</span>             <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123; <span class="comment">// existing mapping for key</span></span><br><span class="line"><span class="number">30</span>                 V oldValue = e.value;</span><br><span class="line"><span class="number">31</span>                 <span class="keyword">if</span> (!onlyIfAbsent || oldValue == <span class="keyword">null</span>)</span><br><span class="line"><span class="number">32</span>                     e.value = value;</span><br><span class="line"><span class="number">33</span>                 afterNodeAccess(e);</span><br><span class="line"><span class="number">34</span>                 <span class="keyword">return</span> oldValue;</span><br><span class="line"><span class="number">35</span>             &#125;</span><br><span class="line"><span class="number">36</span>         &#125;</span><br><span class="line"><span class="number">37</span>         ++modCount;</span><br><span class="line"><span class="number">38</span>         <span class="keyword">if</span> (++size &gt; threshold)</span><br><span class="line"><span class="number">39</span>             resize();</span><br><span class="line"><span class="number">40</span>         afterNodeInsertion(evict);</span><br><span class="line"><span class="number">41</span>         <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line"><span class="number">42</span>     &#125;</span><br></pre></td></tr></table></figure>

<p>这是jdk1.8中HashMap中put操作的主函数， 注意第6行代码，如果没有hash碰撞则会直接插入元素。如果线程A和线程B同时进行put操作，刚好这两条不同的数据hash值一样，并且该位置数据为null，所以这线程A、B都会进入第6行代码中。假设一种情况，线程A进入后还未进行数据插入时挂起，而线程B正常执行，从而正常插入数据，然后线程A获取CPU时间片，此时线程A不用再进行hash判断了，问题出现：线程A会把线程B插入的数据给<strong>覆盖</strong>，发生线程不安全。</p>
<p>这里只是简要分析下jdk1.8中HashMap出现的线程不安全问题的体现，后续将会对java的集合框架进行总结，到时再进行具体分析。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>首先HashMap是不安全的，其主要体现:</p>
<ol>
<li>在jdk1.7中，多线程环境下，扩容时会造成环形链表或丢失数据</li>
<li>在jdk18中，多线程环境下，会发生数据覆盖的情况</li>
</ol>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/01/04/java/5/">HashMap1.8源码分析</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-01-04</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Java/">Java</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Java/">Java</a></span><div class="content"><hr>
<p>该篇博客不适合小白，只做针对性的api源码解析，以及适合我自身的案例研究</p>
<hr>
<h3 id="HashMap构造函数"><a href="#HashMap构造函数" class="headerlink" title="HashMap构造函数"></a>HashMap构造函数</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashMap</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractMap</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt;</span></span><br><span class="line"><span class="class">    <span class="keyword">implements</span> <span class="title">Map</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt;, <span class="title">Cloneable</span>, <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 初始容量</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_INITIAL_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">4</span>; <span class="comment">// aka 16</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 最大容量2的30次方</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAXIMUM_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">30</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 负载因子</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">float</span> DEFAULT_LOAD_FACTOR = <span class="number">0.75f</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 链表转树的阈值</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TREEIFY_THRESHOLD = <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 树转链表的阈值</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> UNTREEIFY_THRESHOLD = <span class="number">6</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 树最小的子节点数</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MIN_TREEIFY_CAPACITY = <span class="number">64</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 默认初始容量是16，负载因子是0.75</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.loadFactor = DEFAULT_LOAD_FACTOR; <span class="comment">// all other fields defaulted</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 只传入初始容量</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(initialCapacity, DEFAULT_LOAD_FACTOR);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 传入初始容量和负载因子</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (initialCapacity &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal initial capacity: "</span> +</span><br><span class="line">                                               initialCapacity);</span><br><span class="line">        <span class="keyword">if</span> (initialCapacity &gt; MAXIMUM_CAPACITY)</span><br><span class="line">            initialCapacity = MAXIMUM_CAPACITY;</span><br><span class="line">        <span class="keyword">if</span> (loadFactor &lt;= <span class="number">0</span> || Float.isNaN(loadFactor))</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal load factor: "</span> +</span><br><span class="line">                                               loadFactor);</span><br><span class="line">        <span class="keyword">this</span>.loadFactor = loadFactor;</span><br><span class="line">        <span class="keyword">this</span>.threshold = tableSizeFor(initialCapacity);</span><br><span class="line">    &#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 传入一个map集合</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(Map&lt;? extends K, ? extends V&gt; m)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.loadFactor = DEFAULT_LOAD_FACTOR;</span><br><span class="line">        putMapEntries(m, <span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="HashMap的数据结构"><a href="#HashMap的数据结构" class="headerlink" title="HashMap的数据结构"></a>HashMap的数据结构</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span></span><br><span class="line"><span class="class">    <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">// hash值</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> hash;</span><br><span class="line">    <span class="comment">// key值</span></span><br><span class="line">    <span class="keyword">final</span> K key;</span><br><span class="line">    <span class="comment">// value值</span></span><br><span class="line">    V value;</span><br><span class="line">    <span class="comment">// 下一个Node的指针</span></span><br><span class="line">    Node&lt;K,V&gt; next;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 构造方法</span></span><br><span class="line">    Node(<span class="keyword">int</span> hash, K key, V value, Node&lt;K,V&gt; next) &#123;</span><br><span class="line">        <span class="keyword">this</span>.hash = hash;</span><br><span class="line">        <span class="keyword">this</span>.key = key;</span><br><span class="line">        <span class="keyword">this</span>.value = value;</span><br><span class="line">        <span class="keyword">this</span>.next = next;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 得到key值</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> K <span class="title">getKey</span><span class="params">()</span>        </span>&#123; <span class="keyword">return</span> key; &#125;</span><br><span class="line">    <span class="comment">// 得到vaue值</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> V <span class="title">getValue</span><span class="params">()</span>      </span>&#123; <span class="keyword">return</span> value; &#125;</span><br><span class="line">    <span class="comment">// 重写toString</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> key + <span class="string">"="</span> + value; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// hashCode值等于key和value的hash值取反</span></span><br><span class="line">        <span class="keyword">return</span> Objects.hashCode(key) ^ Objects.hashCode(value);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 修改value</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> V <span class="title">setValue</span><span class="params">(V newValue)</span> </span>&#123;</span><br><span class="line">        V oldValue = value;</span><br><span class="line">        value = newValue;</span><br><span class="line">        <span class="keyword">return</span> oldValue;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 判断内容相等</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (o == <span class="keyword">this</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">if</span> (o <span class="keyword">instanceof</span> Map.Entry) &#123;</span><br><span class="line">            Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o;</span><br><span class="line">            <span class="keyword">if</span> (Objects.equals(key, e.getKey()) &amp;&amp;</span><br><span class="line">                Objects.equals(value, e.getValue()))</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="重温jdk1-7中如何触发死循环的"><a href="#重温jdk1-7中如何触发死循环的" class="headerlink" title="重温jdk1.7中如何触发死循环的"></a>重温jdk1.7中如何触发死循环的</h3><p>单线程情况下，rehash无问题。下图演示了单线程条件下的rehash过程</p>
<p><img src="https://yerias.github.io/java_img/java_1.png" alt="单线程rehash"></p>
<p>多线程并发下的rehash</p>
<p>这里假设有两个线程同时执行了put操作并引发了rehash，执行了transfer方法，并假设线程一进入transfer方法并执行完next = e.next后，因为线程调度所分配时间片用完而“暂停”，此时线程二完成了transfer方法的执行。此时状态如下。</p>
<p><img src="https://yerias.github.io/java_img/java_2.png" alt="多线程rehash"></p>
<p>接着线程1被唤醒，继续执行第一轮循环的剩余部分</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">e.next = newTable[<span class="number">1</span>] = <span class="keyword">null</span></span><br><span class="line">newTable[<span class="number">1</span>] = e = key(<span class="number">5</span>)</span><br><span class="line">e = next = key(<span class="number">9</span>)</span><br></pre></td></tr></table></figure>

<p>结果如下图所示</p>
<p><img src="https://yerias.github.io/java_img/java_3.png" alt="多线程rehash"></p>
<p>接着线程1被唤醒，继续执行第一轮循环的剩余部分</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">e.next = newTable[<span class="number">1</span>] = <span class="keyword">null</span></span><br><span class="line">newTable[<span class="number">1</span>] = e = key(<span class="number">5</span>)</span><br><span class="line">e = next = key(<span class="number">9</span>)</span><br></pre></td></tr></table></figure>

<p>结果如下图所示</p>
<p><img src="https://yerias.github.io/java_img/java_5.png" alt="多线程rehash"></p>
<p>接着执行下一轮循环，结果状态图如下所示</p>
<p><img src="https://yerias.github.io/java_img/java_4.png" alt="多线程rehash"></p>
<p>此时循环链表形成，并且key(11)无法加入到线程1的新数组。在下一次访问该链表时会出现死循环。</p>
<h3 id="resize"><a href="#resize" class="headerlink" title="resize()"></a>resize()</h3><p>初始化容量16，负载因子0.75，尾插法，扩容2倍，8个节点转树，6个节点转链表，不会产生死循环</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> Node&lt;K,V&gt;[] resize() &#123;</span><br><span class="line">	<span class="comment">// 理解为node/hashmap</span></span><br><span class="line">    Node&lt;K,V&gt;[] oldTab = table;</span><br><span class="line">	<span class="comment">// 拿到旧的hashmapnode的长度</span></span><br><span class="line">    <span class="keyword">int</span> oldCap = (oldTab == <span class="keyword">null</span>) ? <span class="number">0</span> : oldTab.length;</span><br><span class="line">	<span class="comment">// 旧hashmap的扩容阈值</span></span><br><span class="line">    <span class="keyword">int</span> oldThr = threshold;</span><br><span class="line">	<span class="comment">// 新hashmap的容量和阈值初始化为0</span></span><br><span class="line">    <span class="keyword">int</span> newCap, newThr = <span class="number">0</span>;</span><br><span class="line">	<span class="comment">// 拿到新hashmap的容量</span></span><br><span class="line">    <span class="keyword">if</span> (oldCap &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 旧的hashmap容量大于最大值，则直接返回</span></span><br><span class="line">		<span class="keyword">if</span> (oldCap &gt;= MAXIMUM_CAPACITY) &#123;</span><br><span class="line">            threshold = Integer.MAX_VALUE;</span><br><span class="line">            <span class="keyword">return</span> oldTab;</span><br><span class="line">        &#125;</span><br><span class="line">		<span class="comment">// 旧的hashmap扩容为原来的两倍</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> ((newCap = oldCap &lt;&lt; <span class="number">1</span>) &lt; MAXIMUM_CAPACITY &amp;&amp;</span><br><span class="line">                 oldCap &gt;= DEFAULT_INITIAL_CAPACITY)</span><br><span class="line">            newThr = oldThr &lt;&lt; <span class="number">1</span>; </span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">// 旧的hashmap长度等于0，但是阈值大于0，则把阈值赋值为hashmap的长度</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (oldThr &gt; <span class="number">0</span>) </span><br><span class="line">        newCap = oldThr;</span><br><span class="line">	<span class="comment">// 如果旧的hashmap的长度和阈值都为0，则赋初始值</span></span><br><span class="line">    <span class="keyword">else</span> &#123;               </span><br><span class="line">        newCap = DEFAULT_INITIAL_CAPACITY;</span><br><span class="line">        newThr = (<span class="keyword">int</span>)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">// 拿到新阈值的值 =&gt; 新容量*0.75</span></span><br><span class="line">    <span class="keyword">if</span> (newThr == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">float</span> ft = (<span class="keyword">float</span>)newCap * loadFactor;</span><br><span class="line">        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (<span class="keyword">float</span>)MAXIMUM_CAPACITY ?</span><br><span class="line">                  (<span class="keyword">int</span>)ft : Integer.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">// 赋值给threshold</span></span><br><span class="line">    threshold = newThr;</span><br><span class="line">    <span class="meta">@SuppressWarnings</span>(&#123;<span class="string">"rawtypes"</span>,<span class="string">"unchecked"</span>&#125;)</span><br><span class="line">	<span class="comment">// 创建一个新的容量的Node</span></span><br><span class="line">    Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])<span class="keyword">new</span> Node[newCap];</span><br><span class="line">	<span class="comment">// 赋值给table</span></span><br><span class="line">    table = newTab;</span><br><span class="line">	<span class="comment">// 尾插法，将旧的table的数据查询出来再插入新的table</span></span><br><span class="line">    <span class="keyword">if</span> (oldTab != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; oldCap; ++j) &#123;</span><br><span class="line">            Node&lt;K,V&gt; e;</span><br><span class="line">            <span class="keyword">if</span> ((e = oldTab[j]) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                oldTab[j] = <span class="keyword">null</span>;</span><br><span class="line">                <span class="keyword">if</span> (e.next == <span class="keyword">null</span>)</span><br><span class="line">                    newTab[e.hash &amp; (newCap - <span class="number">1</span>)] = e;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (e <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">                    ((TreeNode&lt;K,V&gt;)e).split(<span class="keyword">this</span>, newTab, j, oldCap);</span><br><span class="line">                <span class="keyword">else</span> &#123; <span class="comment">// preserve order</span></span><br><span class="line">                    Node&lt;K,V&gt; loHead = <span class="keyword">null</span>, loTail = <span class="keyword">null</span>;</span><br><span class="line">                    Node&lt;K,V&gt; hiHead = <span class="keyword">null</span>, hiTail = <span class="keyword">null</span>;</span><br><span class="line">                    Node&lt;K,V&gt; next;</span><br><span class="line">                    <span class="keyword">do</span> &#123;</span><br><span class="line">                        next = e.next;</span><br><span class="line">                        <span class="keyword">if</span> ((e.hash &amp; oldCap) == <span class="number">0</span>) &#123;</span><br><span class="line">                            <span class="keyword">if</span> (loTail == <span class="keyword">null</span>)</span><br><span class="line">                                loHead = e;</span><br><span class="line">                            <span class="keyword">else</span></span><br><span class="line">                                loTail.next = e;</span><br><span class="line">                            loTail = e;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">else</span> &#123;</span><br><span class="line">                            <span class="keyword">if</span> (hiTail == <span class="keyword">null</span>)</span><br><span class="line">                                hiHead = e;</span><br><span class="line">                            <span class="keyword">else</span></span><br><span class="line">                                hiTail.next = e;</span><br><span class="line">                            hiTail = e;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; <span class="keyword">while</span> ((e = next) != <span class="keyword">null</span>);</span><br><span class="line">                    <span class="keyword">if</span> (loTail != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        loTail.next = <span class="keyword">null</span>;</span><br><span class="line">                        newTab[j] = loHead;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">if</span> (hiTail != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        hiTail.next = <span class="keyword">null</span>;</span><br><span class="line">                        newTab[j + oldCap] = hiHead;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">// 返回新的Node</span></span><br><span class="line">    <span class="keyword">return</span> newTab;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="hash"><a href="#hash" class="headerlink" title="hash()"></a>hash()</h3><p>使用时异或求hash值，比取余更快更均匀</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> h;</span><br><span class="line">    <span class="comment">// '^' 异或操作，相同则为0，不同则为1</span></span><br><span class="line">    <span class="keyword">return</span> (key == <span class="keyword">null</span>) ? <span class="number">0</span> : (h = key.hashCode()) ^ (h &gt;&gt;&gt; <span class="number">16</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="put"><a href="#put" class="headerlink" title="put()"></a>put()</h3><p>如果插入的位置为空则直接插入，如果有值但是key的hash或者内容相等，则覆盖，如果能转树则转树。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 调用putVal方法</span></span><br><span class="line">    <span class="keyword">return</span> putVal(hash(key), key, value, <span class="keyword">false</span>, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">final</span> V <span class="title">putVal</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, <span class="keyword">boolean</span> onlyIfAbsent,</span></span></span><br><span class="line"><span class="function"><span class="params">               <span class="keyword">boolean</span> evict)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; <span class="keyword">int</span> n, i;</span><br><span class="line">    <span class="comment">// 如果当前数组table为null，进行resize()初始化，n = resize的长度</span></span><br><span class="line">    <span class="keyword">if</span> ((tab = table) == <span class="keyword">null</span> || (n = tab.length) == <span class="number">0</span>)</span><br><span class="line">        n = (tab = resize()).length;</span><br><span class="line">    <span class="comment">// 如果table[i]为空，那就把这个键值对放在table[i]</span></span><br><span class="line">    <span class="keyword">if</span> ((p = tab[i = (n - <span class="number">1</span>) &amp; hash]) == <span class="keyword">null</span>)</span><br><span class="line">        tab[i] = newNode(hash, key, value, <span class="keyword">null</span>);</span><br><span class="line">    <span class="comment">// 当另一个key的hash值已经存在时</span></span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        Node&lt;K,V&gt; e; K k;</span><br><span class="line">        <span class="comment">// 如果节点的key的hash值和容量都相同，则覆盖</span></span><br><span class="line">        <span class="keyword">if</span> (p.hash == hash &amp;&amp;</span><br><span class="line">            ((k = p.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">            e = p;</span><br><span class="line">        <span class="comment">// Node转成树</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (p <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(<span class="keyword">this</span>, tab, hash, key, value);</span><br><span class="line">        <span class="comment">// 遍历table[i]所对应的链表，直到最后一个节点的next为null或者有重复的key值</span></span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> binCount = <span class="number">0</span>; ; ++binCount) &#123;</span><br><span class="line">                <span class="keyword">if</span> ((e = p.next) == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    p.next = newNode(hash, key, value, <span class="keyword">null</span>);</span><br><span class="line">                    <span class="keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD - <span class="number">1</span>)</span><br><span class="line">                        treeifyBin(tab, hash);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (e.hash == hash &amp;&amp;</span><br><span class="line">                    ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                p = e;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// key重复，替换value</span></span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">            V oldValue = e.value;</span><br><span class="line">            <span class="keyword">if</span> (!onlyIfAbsent || oldValue == <span class="keyword">null</span>)</span><br><span class="line">                e.value = value;</span><br><span class="line">            afterNodeAccess(e);</span><br><span class="line">            <span class="keyword">return</span> oldValue;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ++modCount;</span><br><span class="line">    <span class="comment">// 触发扩容</span></span><br><span class="line">    <span class="keyword">if</span> (++size &gt; threshold)</span><br><span class="line">        resize();</span><br><span class="line">    afterNodeInsertion(evict);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="get"><a href="#get" class="headerlink" title="get()"></a>get()</h3><p>首先通过<code>hash</code>函数找到索引，然后判断map为null，再判断table[i]是否等于key，然后在找与table相连的链表的key是否相等。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">	Node&lt;K,V&gt; e;</span><br><span class="line">	<span class="comment">// 如果拿出来的不为null，就返回value</span></span><br><span class="line">	<span class="keyword">return</span> (e = getNode(hash(key), key)) == <span class="keyword">null</span> ? <span class="keyword">null</span> : e.value;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">final</span> Node&lt;K,V&gt; <span class="title">getNode</span><span class="params">(<span class="keyword">int</span> hash, Object key)</span> </span>&#123;</span><br><span class="line">Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; <span class="keyword">int</span> n; K k;</span><br><span class="line"><span class="keyword">if</span> ((tab = table) != <span class="keyword">null</span> &amp;&amp; (n = tab.length) &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">	(first = tab[(n - <span class="number">1</span>) &amp; hash]) != <span class="keyword">null</span>) &#123;</span><br><span class="line">		<span class="comment">// 如果是第一个元素就返回</span></span><br><span class="line">	<span class="keyword">if</span> (first.hash == hash &amp;&amp; <span class="comment">// always check first node</span></span><br><span class="line">		((k = first.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">		<span class="keyword">return</span> first;</span><br><span class="line">		</span><br><span class="line">	<span class="keyword">if</span> ((e = first.next) != <span class="keyword">null</span>) &#123;</span><br><span class="line">		<span class="comment">//// 从树中拿</span></span><br><span class="line">		<span class="keyword">if</span> (first <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">			<span class="keyword">return</span> ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);</span><br><span class="line">		<span class="keyword">do</span> &#123;</span><br><span class="line">			<span class="comment">// 循环链表，key的hash值或者key的内容相同，则返回</span></span><br><span class="line">			<span class="keyword">if</span> (e.hash == hash &amp;&amp;</span><br><span class="line">				((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">				<span class="keyword">return</span> e;</span><br><span class="line">			&#125; <span class="keyword">while</span> ((e = e.next) != <span class="keyword">null</span>);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// 没找到 返回null</span></span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>面试题：如果new HashMap(19)，bucket数组多大？</p>
<ul>
<li>HashMap的bucket 数组大小一定是2的幂，如果new的时候指定了容量且不是2的幂，实际容量会是最接近(大于)指定容量的2的幂，比如 new HashMap&lt;&gt;(19)，比19大且最接近的2的幂是32，实际容量就是32。</li>
</ul>
<p>基础知识</p>
<p><img src="https://yerias.github.io/java_img/%E4%BD%8D%E8%BF%90%E7%AE%97.png" alt="位运算"></p>
</div><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/6/">&lt;&lt;</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/8/">&gt;&gt;</a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2020 By Tunan</div><div class="framework-info"><span>Driven - </span><a href="#"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="#"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>