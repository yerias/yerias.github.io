<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="BigData Developer"><meta name="keywords" content="yerias,TUNANのBlog,BigData"><meta name="author" content="Tunan"><meta name="copyright" content="Tunan"><title>对大数据有颗热诚的心 | TUNANのBlog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="author-info"><div class="author-info__avatar text-center"><img src="/img/xiaoqi.jpg"></div><div class="author-info__name text-center">Tunan</div><div class="author-info__description text-center">BigData Developer</div><div class="follow-button"><a href="#">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">105</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">25</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">21</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="https://hadoop.apache.org/docs/r2.10.0/hadoop-project-dist/hadoop-common/SingleCluster.html" target="_blank" rel="noopener">HADOOP</a><a class="author-info-links__name text-center" href="https://cwiki.apache.org/confluence/display/Hive/" target="_blank" rel="noopener">HIVE</a><a class="author-info-links__name text-center" href="http://archive.cloudera.com/cdh5/cdh/5/" target="_blank" rel="noopener">CDH</a><a class="author-info-links__name text-center" href="http://flume.apache.org/" target="_blank" rel="noopener">FLUME</a><a class="author-info-links__name text-center" href="https://azkaban.github.io/" target="_blank" rel="noopener">AZKABAN</a><a class="author-info-links__name text-center" href="https://www.maxinhong.com/" target="_blank" rel="noopener">叶梨子</a><a class="author-info-links__name text-center" href="https://www.cnblogs.com/qingyunzong" target="_blank" rel="noopener">老铁</a><a class="author-info-links__name text-center" href="https://blog.csdn.net/jim8973/" target="_blank" rel="noopener">飞哥</a></div></div></div><nav id="nav" style="background-image: url(/img/soroush-golpoor-1497416-unsplash.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">TUNANのBlog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">主页</a><a class="site-page" href="/archives">归档</a><a class="site-page" href="/tags">标签</a><a class="site-page" href="/categories">分类</a></span></div><div id="site-info"><div id="site-title">TUNANのBlog</div><div id="site-sub-title">对大数据有颗热诚的心</div><div id="site-social-icons"><a class="social-icon"><i class="fa-github fa"></i></a><a class="social-icon"><i class="fa-weibo fa"></i></a><a class="social-icon"><i class="fa-rss fa"></i></a></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/15/jvm/1/">JVM之运行时数据区</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-15</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Java/">Java</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Java/">Java</a></span><div class="content">目录
jvm命令
jvm的运行时数据区
jvm会发生哪些ERROR
从一个class出发理解数据区

jvm命令JVM参数类型
标准: 稳定的，长期没有变化
X: 相对变化较少的
XX: 变化较大，JVM调优重点

设置参数时，idea指定在VM options里面，命令行直接加在java命令后
j ...</div><a class="more" href="/2020/04/15/jvm/1/#more" style="margin-top: 14px">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/15/spark/16/">从jdbc的角度解读外部数据源</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-15</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Spark/">Spark</a></span><div class="content">接口首先了解三个trait，分别是BaseRelation、TableScan/PrunedScan/PrunedFilteredScan、InsertableRelation，他们的功能在源码中解读。
//代表了一个抽象的数据源。该数据源由一行行有着已知schema的数据组成（关系表）。abstr ...</div><a class="more" href="/2020/04/15/spark/16/#more" style="margin-top: 14px">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/13/spark/15/">RDD转换DadaFrame&amp;使用SQL操作数据源&amp;跨数据源join&amp;SQL与DF与DS的比较Spark元数据管理: catalog</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-13</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Spark/">Spark</a></span><div class="content">目录
RDD转换DadaFrame
使用SQL操作数据源
跨数据源join
SQL与DF与DS的比较
Spark元数据管理: catalog

RDD转换DadaFrame
第一种方式是使用反射来推断包含特定对象类型的RDD的模式
object reflect &#123;    def main( ...</div><a class="more" href="/2020/04/13/spark/15/#more" style="margin-top: 14px">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/10/spark/14/">SparkCore的调优之开发调优</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-10</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Spark/">Spark</a></span><div class="content">目录
调优概述
原则一：避免创建重复的RDD
原则二：尽可能复用同一个RDD
原则三：对多次使用的RDD进行持久化
原则四：尽量避免使用shuffle类算子
原则五：使用map-side预聚合的shuffle操作
原则六：使用高性能的算子
原则七：广播大变量
原则八：使用Kryo优化序列化性能
原则 ...</div><a class="more" href="/2020/04/10/spark/14/#more" style="margin-top: 14px">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/10/spark/13/">Spark源码之解读spark-shell脚本</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-10</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Spark/">Spark</a></span><div class="content">该篇文章主要分析一下Spark源码中启动spark-shell脚本的处理逻辑，从spark-shell一步步深入进去看看任务提交的整体流程

spark-shell脚本解读
# 初始化cygwin=falsecygwin=false# 检查你的系统是否属于cygwincase "$(uname)"  ...</div><a class="more" href="/2020/04/10/spark/13/#more" style="margin-top: 14px">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/10/azkaban/2/">Azkaban配置Plugin实现Spark作业提交(非Shell)</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-10</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Azkaban/">Azkaban</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Azkaban/">Azkaban</a></span><div class="content">第一步，我们要打开azkaban的官网，配置一些文件和参数，如图所示

将spark、common.properties、commonprivate.properties拷贝到服务器中对应的目录，最终的文件展示如下
[hadoop@hadoop jobtypes]$ tree.├── commonp ...</div><a class="more" href="/2020/04/10/azkaban/2/#more" style="margin-top: 14px">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/10/spark/12/">Spark中的序列化</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-10</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Spark/">Spark</a></span><div class="content">在写Spark应用时，常常会碰到序列化的问题。例如，在Driver端的程序中创建了一个对象，而在各个Executor端会用到这个对象——由于Driver端的代码和Executor端的代码在不同的JVM中，甚至在不同的节点上，因此必然要有相应
Java框架进行序列化在默认情况下，Spark会使用Jav ...</div><a class="more" href="/2020/04/10/spark/12/#more" style="margin-top: 14px">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/10/spark/10/">Spark之分组TopN模块</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-10</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Spark/">Spark</a></span><div class="content">在Spark中，分组TopN好写，但是如果想写出性能好的代码却也很难。下面我们将通过写TopN的方式，找出问题，解决问题。

直接reduceByKey完成分组求和排序
def main(args: Array[String]): Unit = &#123;    val in = "file:// ...</div><a class="more" href="/2020/04/10/spark/10/#more" style="margin-top: 14px">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/03/spark/11/">SparkSQL&amp;DataFrame的read和write&amp;SparkSQL做统计分析&amp;UDF函数&amp;存储格式的转换</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-03</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Spark/">Spark</a></span><div class="content">目录
SparkSQL
DataFrame的read和write
SparkSQL做统计分析
UDF函数
存储格式的转换

SparkSQL认识SparkSQL
SparkSQL的进化之路
1.0以前：   Shark1.1.x开始：   SparkSQL(只是测试性的) SQL1.3.x:   S ...</div><a class="more" href="/2020/04/03/spark/11/#more" style="margin-top: 14px">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/02/spark/9/">经典案例&amp;多目录输出&amp;计数器&amp;持久化&amp;广播变量</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-02</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Spark/">Spark</a></span><div class="content">目录
经典案例
多目录输出
计数器
持久化
广播变量

经典案例/** * 用户     节目            展示 点击 * 001,一起看|电视剧|军旅|亮剑,1,1 * 001,一起看|电视剧|军旅|亮剑,1,0 * 002,一起看|电视剧|军旅|士兵突击,1,1 * ==&gt; *  ...</div><a class="more" href="/2020/04/02/spark/9/#more" style="margin-top: 14px">Read more</a><hr></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/2/">&gt;&gt;</a></div></nav></div></div><footer class="footer-bg" style="background-image: url(/img/soroush-golpoor-1497416-unsplash.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2020 By Tunan</div><div class="framework-info"><span>Driven - </span><a href="#"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="#"><span>Melody</span></a></div><div class="footer_custom_text">大家好，我是图南，很高兴认识你们！</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>